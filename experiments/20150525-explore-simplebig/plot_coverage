#!/usr/bin/env python2

import csv
import itertools
import random
import sys
import os

import numpy as np

import matplotlib.pyplot as plt
from matplotlib.ticker import FormatStrFormatter
import seaborn as sns

import labm8
from labm8 import io
from labm8 import fs
from labm8 import make
from labm8 import system

import omnitune
from omnitune import skelcl

import experiment


def get_runtimes(db, where, wg_c, wg_r):
    where += " AND wg_c={c} AND wg_r={r}".format(c=wg_c, r=wg_r)
    query = db.execute("SELECT runtime FROM runtimes WHERE " + where)
    return [row[0] for row in query]


def plot_runtimes(runtimes):
    """
    Plot the distribution of a set of runtimes.
    """
    plt.hist(runtimes, 100)
    plt.title("Distribution of {0} runtimes".format(len(runtimes)))
    plt.ylabel("Frequencey")
    plt.xlabel("Runtime (ms)")
    plt.show()

def get_name(data):
    c = ["Kernel ",
         data["kern_checksum"][:8],
         " on ",
         data["host"],
         ", using "]

    if int(data["dev_count"] > 1):
        c += [data["dev_count"], "x "]

    c += [
        data["dev_name"].strip(),
        ".\nData size: ",
        data["data_width"], "x", data["data_height"],
        ". Border size: ",
        ",".join([data["north"],
                  data["south"],
                  data["east"],
                  data["west"]]),
        "."
    ]

    return "".join(c)


image_count = 0

def plot_heatmaps(samplecounts_data, runtimes_data):
    global image_count

    sample_counts = np.zeros(shape=(len(skelcl.WG_VALUES),
                                    len(skelcl.WG_VALUES)))
    runtimes = np.zeros(shape=(len(skelcl.WG_VALUES),
                                    len(skelcl.WG_VALUES)))

    for wg in itertools.product(skelcl.WG_VALUES, skelcl.WG_VALUES):
        j = len(skelcl.WG_VALUES) - 1 - skelcl.WG_VALUES.index(wg[0])
        i = skelcl.WG_VALUES.index(wg[1])
        key = str(wg[0]) + "x" + str(wg[1])

        sample_counts[j][i] = int(samplecounts_data[key])
        runtimes[j][i] = float(runtimes_data[key])

    name = get_name(samplecounts_data)

    f, ax = plt.subplots(figsize=(12, 9))
    sns.heatmap(sample_counts, linewidths=0, square=True,
                vmin=0,
                xticklabels=skelcl.WG_VALUES,
                yticklabels=list(reversed(skelcl.WG_VALUES)))
    plt.title(name)
    plot_path = "img/samplecounts/{0:04d}.png".format(image_count)
    io.info(plot_path)
    plt.savefig(plot_path)
    plt.close()


    f, ax = plt.subplots(figsize=(12, 9))
    sns.heatmap(runtimes, linewidths=0, square=True,
                vmin=runtimes.min(), vmax=runtimes.max(),
                xticklabels=skelcl.WG_VALUES,
                yticklabels=list(reversed(skelcl.WG_VALUES)))
    plt.title(name)
    plot_path = "img/runtimes/{0:04d}.png".format(image_count)
    io.info(plot_path)
    plt.savefig(plot_path)
    plt.close()

    image_count += 1


def plot_best_wg_counts(best_wg_counts):
    """
    Visualise the "best workgroup counts" data.

    * A heatmap of the number of times that a workgroup size was
      optimal.
    * A sorted frequency plot showing how many times a value was
      optimal.

    Arguments:

        best_wg_counts (np.matrix of ints): A matrix of every point in
          the WG_VALUES search space, with the value being the number
          of times that the wg size was optimal.
    """
    sum_best_wg_counts = best_wg_counts.sum()

    f, ax = plt.subplots(figsize=(12, 9))

    freq = np.squeeze(np.asarray(best_wg_counts))
    pos_freq = sorted([f for f in np.nditer(freq) if f > 0], reverse=True)

    median_pos_freq = np.median(pos_freq)
    #center=flights_rect.loc["January", 1955]


    sns.heatmap(best_wg_counts, linewidths=0, square=True,
                # TODO: Remove this artificial clamp.
                vmin=0, vmax=10, cmap="Reds", cbar=False,
                xticklabels=skelcl.WG_VALUES,
                yticklabels=list(reversed(skelcl.WG_VALUES)))

    fontsize = 18
    for tick in ax.xaxis.get_major_ticks():
        tick.label.set_fontsize(fontsize)
    for tick in ax.yaxis.get_major_ticks():
        tick.label.set_fontsize(fontsize)

    plot_path = "img/best_wg_heatmap.png".format(image_count)
    io.info(plot_path)
    plt.gcf().set_size_inches(15.6, 15.6, dpi=300)
    plt.tight_layout()
    plt.savefig(plot_path)
    plt.close()

    # Print the number of unique values needed to be optimal 50% of
    # the time.
    total = 0
    for i,y in enumerate(pos_freq):
        total += y
        if total > 50:
            io.info("Number of unique values needed to be optimal 50% of "
                    "time = ", i)
            break

    # Scale values to be proportional to total number of unique
    # values.
    pos_freq = [(y / sum(pos_freq)) * 100 for y in pos_freq]

    acc = 0
    acc_pos_freq = []
    for freq in pos_freq:
        acc += freq
        acc_pos_freq.append(acc)

    X = np.arange(len(pos_freq))

    plt.scatter(X, acc_pos_freq)
    #plt.title("% of oracle")
    plt.ylabel("% of oracle")
    plt.xlim(xmin=0, xmax=len(pos_freq) - 1)
    plt.ylim(ymin=0, ymax=100)
    plt.xlabel("Number of unique values")
    plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%d %%'))

    plot_path = "img/best_wg_distribution.png".format(image_count)
    io.info(plot_path)
    plt.gcf().set_size_inches(15.6, 5.25, dpi=300)
    plt.tight_layout()
    #plt.show()
    plt.savefig(plot_path)
    plt.close()


def main():
    fs.mkdir("img/samplecounts")
    fs.mkdir("img/runtimes")
    samplecounts_csv = open('csv/samplecounts.csv', 'rb')
    runtimes_csv = open('csv/runtimes.csv', 'rb')

    samplecounts_reader = csv.reader(samplecounts_csv)
    runtimes_reader = csv.reader(runtimes_csv)

    header = samplecounts_reader.next()
    header = runtimes_reader.next()

    best_wg_counts = np.zeros(shape=(len(skelcl.WG_VALUES),
                                     len(skelcl.WG_VALUES)))

    for samplecounts_row in samplecounts_reader:
        runtimes_row = runtimes_reader.next()

        # Create dicts of values.
        samplecounts_data, runtimes_data = {}, {}
        for i,key in enumerate(header):
            samplecounts_data[key] = samplecounts_row[i]
            runtimes_data[key] = runtimes_row[i]

        # Get the workgroup size which gave the lowest runtime.
        pairs = []
        for j in range(11, len(header)):
            runtime = float(runtimes_row[j])
            if runtime > 0:
                pairs.append((header[j], runtime))

        min_pair = min(pairs, key=lambda x: x[1])
        best_wg = tuple([int(x) for x in min_pair[0].split("x")])
        j = len(skelcl.WG_VALUES) - 1 - skelcl.WG_VALUES.index(best_wg[0])
        i = skelcl.WG_VALUES.index(best_wg[1])
        best_wg_counts[j][i] += 1

        # plot_heatmaps(samplecounts_data, runtimes_data)

    # Add negative offset to illegal values
    for j,_ in enumerate(skelcl.WG_VALUES):
        for i,_ in enumerate(skelcl.WG_VALUES):
            c = skelcl.WG_VALUES[i]
            r = skelcl.WG_VALUES[j]

            j = len(skelcl.WG_VALUES) - 1 - j
            if c * r > 4096:
                pass
                #best_wg_counts[j][i] = -1

    plot_best_wg_counts(best_wg_counts)


if __name__ == "__main__":
    main()
