This research will use the Algorithmic Skeleton library
SkelCL\footnote{\url{http://skelcl.uni-muenster.de/}} as the base
platform upon which a dynamic autotuner will be developed. Michel
Steuwer, a research associate at the University of Edinburgh,
developed SkelCL as an approach to high-level programming for
multi-GPU systems~\cite{Steuwer2011,
Steuwer2013a}. \citeauthor{Steuwer2012} demonstrated an $11\times$
reduction in programmer effort compared to equivalent programs
implemented with pure OpenCL, while suffering only a modest 5\%
overhead~\cite{Steuwer2012}.

The core of SkelCL comprises a set of parallel container data types
for vectors and matrices, and an automatic distribution mechanism that
performs implicit transfer of these data structures between the host
and device memory. Application programmers express computations on
these data structures using Algorithmic Skeletons that are
parameterised with small sections of OpenCL code. At runtime, SkelCL
compiles the OpenCL code into compute kernels for execution on
GPUs. This makes SkelCL an excellent candidate for dynamic autotuning,
as it exposes both the optimisation space of the OpenCL compiler, and
the high level tunable parameters provided by the structure of
Algorithmic Skeletons.
% TODO: is this next sentence necessary?
SkelCL offers the unique advantage of being able to amortise many of
the costs associated with dynamic compilation due to its JIT-like
nature of compiling OpenCL kernels immediately before execution.
% TODO: UML sequence diagram of SkelCL

The methodology used in this research will approach the problem in
three stages:

\begin{enumerate}
\item Modify SkelCL to enable the runtime configuration of
optimisation parameters.
\item Evaluate the significance of different optimisation parameters
in order to select the parameters which provide the most profitable
optimisation space.
\item Implement a dynamic autotuner which searches and builds a model
of this optimisation space at runtime.
\end{enumerate}

In the first stage, the SkelCL library will be changed to support
dynamic parameter setting. This will involve a number of modifications
to replace compile-time constant parameters such as the mapping of
threads to work groups and the OpenCL compiler configuration with
equivalent variable parameters which can be set at runtime.

Pilot experiments will then be used to evaluate the effect of
different parameters on performance, by manually varying these runtime
parameters across a range of different inputs and measuring their
impact on performance. Statistical methods will be used to analyse
these results in order to isolate the parameters with the greatest
performance impact. In previous research, Principle Component Analysis
has been used effectively to reduce the dimensionality of optimisation
spaces. This exploratory phase provides opportunities for the novel
use of dynamic features for the purpose of autotuning Algorithmic
Skeletons. Previous research has focused on offline tuning and so has
been restricted to the set of features which can be either statically
determined or approximated. A dynamic autotuner exposes many new
features which cannot be statically determined, such as:

\begin{itemize}
%\itemsep0em
\item properties of the input data, e.g.\ the size, and data type;
\item copy-up and copy-down times for transferring data to and from
  device memory;
\item the number of cores available on devices;
\item OpenCL compiler settings and optimisation flags;
\item runtime environment properties, e.g.\ system load.
\end{itemize}

The final stage will construct a dynamic autotuner that uses the
features selected in the exploratory phase. To the best of our
knowledge, this will be the first attempt to develop a dynamic
autotuner for Algorithmic Skeletons. The focus of the implementation
will be to exploit the advantages of dynamic features to provide
improved performance over existing static Algorithmic Skeleton
autotuners, and to exploit the high-level abstractions of Algorithmic
Skeletons to provide improved performance over existing dynamic
optimisers.

Implementing a dynamic autotuner poses a number of difficult
implementation challenges. The primary challenge is to minimise the
runtime overhead of the dynamic autotuner so that it does not outweigh
the performance gains of the optimisations themselves. The proposed
approach to dynamically autotune SkelCL will overcome one of the most
significant overheads associated with dynamic optimising: that of
instrumenting the code for the purpose of profiling and tracing. Since
Algorithmic Skeletons coordinate muscle functions, it is possible to
forgo many of the profiling counters that dynamic optimisers require
by making assumptions about the execution frequency of certain code
paths, given the nature of the skeleton. Additionally, the placement
of profiling counters can be optimised manually.

The convergence time of autotuning can be improved by saving the
results of trial configurations persistently in a central
database. This provides two primary advantages: first, it allows the
results of autotuning to be used by future invocations of the program;
second, it allows the result of autotuning to be shared amongst
different programs. The challenge of implementing this persistent data
storage is that results must be stored efficiently and compactly, this
is to allow for indefinite scaling of the dataset as future results
are added. Increasing the size of the training dataset also increases
the time required to compute new results, and there is additional
latencies associated with reading and writing data to and from disk.

% TODO: inter-skeleton tuning
