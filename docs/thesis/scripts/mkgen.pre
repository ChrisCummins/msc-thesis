#!/usr/bin/env python2
from __future__ import division
from __future__ import print_function

import csv
import json
import re

from itertools import product

import numpy as np
import matplotlib

# Use Agg backend to silence warnings on OS X.
matplotlib.use('Agg')

import matplotlib.pyplot as plt
import seaborn as sns

from matplotlib.ticker import FormatStrFormatter

import labm8 as lab
from labm8 import fs
from labm8 import io
from labm8 import latex
from labm8 import math as labmath
from labm8 import ml
from labm8 import system
from labm8 import viz

import omnitune
from omnitune import skelcl
from omnitune.skelcl import db as _db
from omnitune.skelcl import unhash_params
from omnitune.skelcl import visualise
from omnitune.skelcl.dataset import Dataset
from omnitune.skelcl.migrate import migrate
from omnitune.skelcl.visualise import fmtdevid
from omnitune.skelcl import space as _space


def mktex(string, path):
    """
    Write a latex data file, appended by a comment sign.
    """
    system.echo("\\checkme{{{}}}%".format(string), path, end="")
    io.info("Wrote", path)


def mktable(name, delimiter=",", escape=False):
    output = "gen/tab/{}.tex".format(name)
    reader = csv.reader(open("dat/{}.csv".format(name)), delimiter=delimiter)
    header = reader.next()
    rows = [row for row in reader]
    latex.table(rows, output=output, columns=header, escape=escape)


def print_params(params):
    wg_c, wg_r = unhash_params(params)
    return "${c} \\times {r}$".format(c=wg_c, r=wg_r)

def print_w(params):
    wg_c, wg_r = unhash_params(params)
    return "w_{{({c} \\times {r})}}".format(c=wg_c, r=wg_r)


#################
# Export tables #
#################
def create_hosts_table(output=None):
    output = output or "gen/tab/hosts.tex"
    reader = csv.reader(open("dat/hosts.csv"), delimiter="\t")
    header = reader.next()
    rows = [row for row in reader]
    latex.table(rows, output=output, columns=header, escape=False)


def create_heuristics_table(output=None):
    output = output or "gen/tab/heuristics-dev.tex"
    reader = csv.reader(open("dat/heuristics-dev.csv"), delimiter="\t")
    header = reader.next()
    rows = [row for row in reader]
    latex.table(rows, output=output, columns=header, escape=False)


def create_stencil_runtime_components_table(output=None):
    output = output or "gen/tab/stencil-runtime-components.tex"
    reader = csv.reader(open("dat/stencil-runtime-components.csv"),
                        delimiter="\t")
    header = reader.next()
    rows = [row for row in reader]
    latex.table(rows, output=output, columns=header, escape=False)


def create_devices_table(db, output=None):
    def _escape_name(name):
        name = name.strip()
        name = re.sub("^\dx", "", name)
        name = re.sub("GeForce", "Nvidia", name)
        name = re.sub("Tahiti", "AMD Tahiti 7970", name)
        name = re.sub("Intel\(R\) Core\(TM\)", "Intel", name)
        name = re.sub(" CPU @ [0-9\.]+GHz", "", name)
        return name

    output = output or "gen/tab/devices.tex"
    infos = set()
    for row in db.execute("SELECT name,max_compute_units,"
                          "max_clock_frequency,local_mem_size,"
                          "global_mem_cache_size,global_mem_size "
                          "FROM devices WHERE id LIKE '1x%'"):
        name,cunits,freq,lmem,gcache,gmem = row
        infos.add((_escape_name(name),
                   cunits,
                   str(freq) + " Hz",
                   str(labmath.ceil(lmem / 1024)) + " KB",
                   str(labmath.ceil(gcache / 1024)) + " KB",
                   str(labmath.ceil(gmem / 1024 / 1024)) + " MB"))

    infos = list(sorted(infos, key=lambda x: x[0]))
    latex.table(infos, output=output, columns=(
        "Name",
        "Compute units",
        "Frequency",
        "Local Memory",
        "Global Cache",
        "Global Memory"
    ))


def create_kernels_table(db, output=None):
    def _process_row(row):
        def _process_kernel(kernel):
            north,south,east,west = db.execute("SELECT north,south,east,west "
                                               "FROM kernels WHERE id=?",
                                               (kernel,)).fetchone()
            instcount = db.execute("SELECT instruction_count FROM "
                                   "kernels where id=?",
                                   (kernel,)).fetchone()[0]
            return name, north, south, east, west, instcount

        name = row[0]
        kernels = db.execute("SELECT id from kernel_names where name=?", (name,)).fetchall()
        return [_process_kernel(row[0]) for row in kernels]

    output = output or "gen/tab/kernels.tex"
    synthetics, real = set(), set()
    for row in db.execute("SELECT DISTINCT name FROM kernel_names WHERE synthetic=1"):
        [synthetics.add(entry) for entry in _process_row(row)]
    for row in db.execute("SELECT DISTINCT name FROM kernel_names WHERE synthetic=0"):
        [real.add(entry) for entry in _process_row(row)]

    synthetics = list(sorted(synthetics, key=lambda x: x[0]))
    real = list(sorted(real, key=lambda x: x[0]))

    latex.table(synthetics + real, output=output, columns=(
        "Name",
        "North",
        "South",
        "East",
        "West",
        "Instruction Count"
    ))

def create_datasets_table(db, output=None):
    output = output or "gen/tab/datasets.tex"
    infos = set(row for row in
                db.execute("SELECT width,height,tin,tout "
                           "FROM datasets"))
    data = list(sorted(infos, key=lambda x: x[0]))
    latex.table(data, output=output, columns=(
        "Width",
        "Height",
        "Type in",
        "Type out"
    ))


def create_results_tables(db):
    # Number of rows to include in tables.
    num_rows = 25

    output = "gen/tab/top_params_coverage.tex"
    data = [
        [print_params(row[0]), round(row[1] * 100, 1), round(row[2] * 100, 1)]
        for row in
        db.execute(
            "SELECT params,coverage,performance "
            "FROM param_stats "
            "ORDER BY coverage DESC, performance DESC "
            "LIMIT ?",
            (num_rows,)
        )
    ]
    latex.table(data, output=output, escape=False, columns=(
        "Parameter",
        "Legality (\\%)",
        "Performance (\\%)",
    ))

    output = "gen/tab/top_params_perf.tex"
    data = [
        [print_params(row[0]), round(row[1] * 100, 1), round(row[2] * 100, 1)]
        for row in
        db.execute(
            "SELECT params,coverage,performance "
            "FROM param_stats "
            "ORDER BY performance DESC,coverage DESC "
            "LIMIT ?",
            (num_rows,)
        )
    ]
    latex.table(data, output=output, escape=False, columns=(
        "Parameter",
        "Legality (\\%)",
        "Performance (\\%)",
    ))


def create_refused_params_tables(db):
    num_rows = 10

    for i in range(3):
        output = "gen/tab/top_refused_params_{}.tex".format(i+1)
        data = [
            [print_params(row[0]), round(row[1], 2)] for row in
            db.execute(
                "SELECT "
                "    params,"
                "    (Count(*) * 1.0 / (SELECT Count(*) FROM refused_params)) "
                "       * 100 AS ratio "
                "FROM refused_params "
                "GROUP BY params "
                "ORDER BY ratio DESC "
                "LIMIT ? "
                "OFFSET ? ",
                (num_rows, i*10)
            )
        ]
        latex.table(data, output=output, escape=False, columns=(
            "Parameter",
            "Refused (\\%)"
        ))


def fine_grained_runtime_histograms():
    sample_runtimes = [
        np.array(l) for l in
        json.load(open(fs.path("~/data/msc-thesis/sample-runtimes.json")))
    ]

    # Found by hand:
    indicies = [
        601, # 2.0406245600000004
        895, # 25.012451818
        480, # 51.718092256000006
        590, # 75.140274775
        941, # 100.372847552
        939, # 100.9115374
        312, # 119.245880346
        437, # 143.98754486299998
        156, # 195.44022449400003
    ]

    for i,index in enumerate(indicies):
        runtimes = sample_runtimes[index]
        output = "gen/img/runtimes_histogram_{}.pdf".format(i+1)
        figsize=(2, 2)
        visualise.runtimes_histogram(runtimes, output=output, figsize=figsize)


def num_samples_vs_variance(db):
    data = json.load(open(fs.path("~/data/msc-thesis/ci.json")))
    figsize=(5.8, 1.8)

    min_samples = db.min_sample_count
    mean_samples = int(round(db.mean_samples))
    X, Y, _ = zip(*data)

    mktex(round(Y[X.index(min_samples)] * 100, 1), "gen/max_ci.tex")
    mktex(round(Y[X.index(mean_samples)] * 100, 1), "gen/mean_ci.tex")
    mktex(mean_samples, "gen/avg_sample_count.tex")

    output = "gen/img/ci_trend.pdf"
    visualise.confinterval_trend(X, Y, vlines=[min_samples, mean_samples],
                                 figsize=figsize, output=output)


def motivating_examples(db):
    import matplotlib.cm as cm
    from mpl_toolkits.mplot3d import Axes3D

    scenarios = [
        "1bb3496330190941d56f5d549c5f11e5ffb25358",
        "6a0f45a9adbd797d40487dac9cbab5979041eaad",
        "7d57091f444292afbc9b79d6d0cb78ef96ada489",
        "75121e48a776fde6d2885b3a1b551f0da7e20b88",
    ]

    for i,scenario in enumerate(scenarios):
        output = fs.path("gen/img/motivation_{}.png".format(i+1))
        space = _space.ParamSpace.from_dict(db.perf_scenario(scenario))
        max_c = min(20, len(space.c))
        max_r = min(20, len(space.r))
        space.reshape(max_c=max_c, max_r=max_r)

        X, Y, dZ = [], [], []

        # Iterate over every point in space.
        for j,i in product(range(space.matrix.shape[0]),
                           range(space.matrix.shape[1])):
            if space.matrix[j][i] > 0:
                element = space.matrix[j][i]

                X.append(i)
                Y.append(j)
                dZ.append(element)

        io.info(db.perf(scenario, "32x4"))

        num_vals = len(X)
        Z = np.zeros((num_vals,))
        dX = np.ones((num_vals,))
        dY = np.ones((num_vals,))

        fig = plt.figure()
        ax = fig.add_subplot(111, projection='3d')
        ax.bar3d(X, Y, Z, dX, dY, dZ)

        # Set X axis labels
        if len(space.c) > 10:
            c = [x if i % 2 else "" for i,x in enumerate(space.c)]
        else:
            c = space.c
        ax.set_xticks(np.arange(len(space.c)))
        ax.set_xticklabels(c)
        ax.set_xlabel("$w_c$")

        # Set Y axis labels
        if len(space.r) > 10:
            r = [x if i % 2 else "" for i,x in enumerate(space.r)]
        else:
            r = space.r
        ax.set_yticks(np.arange(len(space.r)))
        ax.set_yticklabels(r)
        ax.set_ylabel("$w_r$")

        # Set Z axis labels
        ax.set_zlabel("Performance")

        # Set plot rotation.
        ax.view_init(azim=45)

        plt.tight_layout()
        figsize=(3.333,2.667)
        plt.gcf().set_size_inches(*figsize, dpi=300)
        viz.finalise(output)


def classification_heatmaps(db, classifier, job, output):
    predictions = {
        row[0]: row[1] for row in
        db.execute(
            "SELECT predicted,Count(*) FROM classification_results "
            "WHERE classifier=? AND err_fn=? AND job=? "
            "GROUP BY predicted",
            (classifier, "reshape_fn", job)
        )
    }
    actual = {
        row[0]: row[1] for row in
        db.execute(
            "SELECT actual,Count(*) FROM classification_results "
            "WHERE classifier=? AND err_fn=? AND job=? "
            "GROUP BY actual",
            (classifier, "reshape_fn", job)
        )
    }
    space = _space.ParamSpace(range(20, 81, 2), range(0, 61, 2))

    for param,val in predictions.iteritems():
        if space.inspace(param):
            space[param] = val

    # Offset by real
    for param,val in actual.iteritems():
        if space.inspace(param):
            space[param] -= val

    space.heatmap(output=output, title=ml.classifier_basename(classifier),
                  figsize=(2.5,3), vmin=-4, vmax=4, cbar=False)


def regression_heatmaps(db, job, output, table="runtime_classification_results",
                        title="Runtime Regression"):
    predictions = {
        row[0]: row[1] for row in
        db.execute(
            "SELECT predicted,Count(*) FROM {} "
            "WHERE job=? "
            "GROUP BY predicted".format(table),
            (job,)
        )
    }
    actual = {
        row[0]: row[1] for row in
        db.execute(
            "SELECT actual,Count(*) FROM classification_results "
            "WHERE job=? "
            "GROUP BY actual".format(table),
            (job,)
        )
    }
    space = _space.ParamSpace(range(20, 81, 2), range(0, 61, 2))

    for param,val in predictions.iteritems():
        if space.inspace(param):
            space[param] = val

    # Offset by real
    for param,val in actual.iteritems():
        if space.inspace(param):
            space[param] -= val

    space.heatmap(output=output, title=title,
                  figsize=(2.5,3), vmin=-100, vmax=100, cbar=False)


def main():
    ml.start()
    db = migrate(_db.Database("/usr/share/omnitune/db/skelcl.db"))

    # Set plot style.
    sns.set_context("notebook", font_scale=.8, rc={"lines.linewidth": 2})
    sns.set_style("whitegrid")

    from matplotlib import rc
    rc('text', usetex=True)

    # # Delete existing files.
    # fs.rm("gen")
    # fs.mkdir("gen/img")
    # fs.mkdir("gen/tab")

    # ##################
    # # Dynamic values #
    # ##################
    # one_r = db.one_r()
    # mktex(print_params(one_r[0]), "gen/one_r.tex")
    # mktex(round(one_r[2], 2), "gen/one_r_perf.tex")
    # mktex(int(round(one_r[2] * 100)), "gen/baseline_perf_perc.tex")

    # mktex(int(round(db.min_num_params)), "gen/min_num_params.tex")
    # mktex(int(round(db.max_num_params)), "gen/max_num_params.tex")
    # mktex(int(round(db.avg_num_params)), "gen/avg_num_params.tex")

    # mktex(db.num_rows("runtime_stats"), "gen/num_runtime_stats.tex")
    # mktex(db.num_rows("runtimes"), "gen/num_samples.tex")
    # mktex(db.num_rows("scenarios"), "gen/num_scenarios.tex")
    # mktex(db.min_sample_count, "gen/min_sample_count.tex")
    # mktex(db.max_sample_count, "gen/max_sample_count.tex")
    # mktex(db.execute("SELECT Max(num_samples) FROM runtime_stats").fetchone()[0],
    #       "gen/max_sample_count.tex")
    # mktex(len(db.real_kernels), "gen/num_real_kernels.tex")

    # mktex(db.num_params, "gen/num_params.tex")

    # num_oracle_params = db.execute("SELECT Count(*) FROM ("
    #                                "SELECT DISTINCT oracle_param "
    #                                "FROM scenario_stats)").fetchone()[0]

    # mktex(num_oracle_params, "gen/num_oracle_params.tex")
    # mktex(round(db.execute("SELECT (1.0 * {} / "
    #                        "(select count(*) from scenario_stats)) * 100"
    #                        .format(num_oracle_params)).fetchone()[0], 1),
    #       "gen/oracle_params_per_scenario_perc.tex")

    mktable("class")
    mktable("class-runtime")
    mktable("class-speedup")

    # # Oracle param frequencies
    # oracle_params = sorted(db.oracle_param_frequencies(normalise=True).items(),
    #                        reverse=True, key=lambda x: x[1])
    # freqs = [x[1] for x in oracle_params]

    # acc = 0
    # acc_freqs = []
    # for i,freq in enumerate(freqs):
    #     acc += freq
    #     acc_freqs.append(acc)
    #     if acc > .5:
    #         mktex(i + 1, "gen/num_wgsizes_50_accuracy.tex")
    #         break
    # max_oracle_param = oracle_params[0]
    # mktex(print_params(max_oracle_param[0]),
    #       "gen/max_oracle_param.tex")
    # mktex(print_w(max_oracle_param[0]),
    #       "gen/max_oracle_param_w.tex")
    # mktex("${}\\%$".format(int(round(max_oracle_param[1] * 100))),
    #       "gen/max_oracle_param_frequency.tex")


    # # Max speedups
    # max_speedups = sorted(db.max_speedups().values(), reverse=True)
    # mktex(round(max_speedups[0], 2),
    #       "gen/max_possible_speedup.tex")
    # mktex(int(round((1 - 1 / max_speedups[0]) * 100)),
    #       "gen/max_possible_speedup_perc.tex")
    # mktex(round(max_speedups[-1], 2),
    #       "gen/min_possible_speedup.tex")
    # mktex(int(round((1 - 1 / max_speedups[-1]) * 100)),
    #       "gen/min_possible_speedup_perc.tex")
    # mean_possible_speedup = labmath.mean(max_speedups)
    # mktex(round(mean_possible_speedup, 2),
    #       "gen/avg_possible_speedup.tex")
    # mktex(int(round((1 - 1 / mean_possible_speedup) * 100)),
    #       "gen/avg_possible_speedup_perc.tex")

    # # ML speedups
    # best_classification_results = db.best_classification_results
    # best_synthetic_real_classification_results = db.best_synthetic_real_classification_results
    # mktex(int(round(best_classification_results[2])),
    #       "gen/best_avg_classification_performance.tex")
    # mktex(round(best_classification_results[3], 2),
    #       "gen/best_avg_classification_speedup.tex")
    # mktex(round(best_classification_results[4], 2),
    #       "gen/best_max_classification_speedup.tex")

    # mktex(int(round(best_classification_results[5] * 100) - 100),
    #       "gen/best_avg_classification_speedup_he_perc.tex")

    # mktex(int(round(best_synthetic_real_classification_results[2])),
    #       "gen/best_avg_synthetic_real_classification_performance.tex")
    # mktex(round(best_synthetic_real_classification_results[3], 2),
    #       "gen/best_avg_synthetic_real_classification_speedup.tex")
    # mktex(int(round(db.biggest_synthetic_real_classification_performance_drop)),
    #       "gen/biggest_synthetic_real_classification_performance_drop.tex")

    # mktex(round(db.ratio_refused_params * 100, 1),
    #       "gen/ratio_refused_params.tex")
    # mktex(round(db.ratio_refused_test_cases * 100, 1),
    #       "gen/ratio_refused_test_cases.tex")

    # # Tables.
    # create_hosts_table()
    # create_heuristics_table()
    # create_stencil_runtime_components_table()

    # create_devices_table(db)
    # create_kernels_table(db)
    # create_datasets_table(db)
    # create_results_tables(db)
    # create_refused_params_tables(db)

    # ################
    # # Export plots #
    # ################

    # # Variance trends
    # num_samples_vs_variance(db)

    # # Runtime histograms
    # fine_grained_runtime_histograms()

    # # Heatmaps
    # figsize=(5, 4)
    # visualise.oracle_wgsizes(db, "gen/img/oracle_param_space.pdf",
    #                          figsize=figsize, trisurf=True, clip=50,
    #                          title=None, rotation=45,
    # )
    # visualise.coverage(db, "gen/img/coverage_space.pdf",
    #                    figsize=figsize, clip=100, trisurf=True,
    #                    title=None, rotation=45,
    # )
    # visualise.max_wgsizes(db, "gen/img/max_wgsizes.pdf", trisurf=True,
    #                       figsize=figsize, rotation=45, title=None)

    # # figsize=(2.5, 2.5)
    # # visualise.oracle_wgsizes(db, "gen/img/1.pdf",
    # #                          figsize=figsize, clip=50,
    # #                          title=None
    # # )
    # # visualise.performance(db, "gen/img/2.pdf",
    # #                       figsize=figsize, clip=100,
    # #                       title=None,
    # # )
    # # visualise.coverage(db, "gen/img/3.pdf",
    # #                    figsize=figsize, clip=100,
    # #                    title=None,
    # # )
    # # visualise.max_wgsizes(db, "gen/img/4.pdf",
    # #                       figsize=figsize, title=None
    # # )

    # figsize=(3, 2)
    # visualise.num_samples(db, "gen/img/num_samples.pdf", title="",
    #                       figsize=figsize)
    # visualise.num_params(db, "gen/img/num_params.pdf", title="",
    #                      figsize=figsize)

    # figsize=(3, 3)
    # visualise.refused_params_by_device(db,
    #                                    "gen/img/refused_params_by_device.pdf",
    #                                    figsize=figsize)
    # visualise.refused_params_by_vendor(db,
    #                                    "gen/img/refused_params_by_vendor.pdf",
    #                                    figsize=figsize)
    # visualise.refused_param_space(db,
    #                               "gen/img/refused_param_space.pdf",
    #                               figsize=figsize)

    # # Trend plots
    # figsize=(5.8,3.5)
    # visualise.max_speedups(db, "gen/img/max_speedups.pdf", title="",
    #                        figsize=figsize)
    # figsize=(5.8,2)
    # visualise.num_params_vs_accuracy(db, "gen/img/num_params_oracle.pdf",
    #                                  title="", figsize=figsize)

    # figsize=(4.5,4)
    # visualise.performance_vs_coverage(db, "gen/img/params_summary.pdf",
    #                                   figsize=figsize)

    # # Boxplots grouped by kernel,device,dataset
    # boxplot_height = 3.5

    # figsize=(5.8, boxplot_height) # Full page width
    # visualise.kernel_performance(db, "gen/img/performance_kernels.pdf",
    #                              title="", figsize=figsize)
    # figsize=(5.8/2, boxplot_height) # Half-width
    # visualise.device_performance(db, "gen/img/performance_devices.pdf",
    #                              title="", figsize=figsize)
    # visualise.dataset_performance(db, "gen/img/performance_datasets.pdf",
    #                               title="", figsize=figsize)

    # # Boxplots grouped by wgsize
    # figsize=(5.8, boxplot_height)
    # ratios = [np.array(l) for l in
    #           json.load(open(fs.path(
    #               "~/data/msc-thesis/performance_wgsize.json"
    #           )))]
    # visualise.performance_vs_max_wgsize(ratios,
    #                                     "gen/img/performance_max_wgsize.pdf",
    #                                     xlabel="Workgroup size (\\% max)",
    #                                     figsize=figsize,
    #                                     color=sns.color_palette("Greens"))

    # figsize=(5.8/2, boxplot_height) # Half-width
    # ratios = [np.array(l) for l in
    #           json.load(open(fs.path(
    #               "~/data/msc-thesis/performance_c.json"
    #           )))]
    # visualise.performance_vs_max_wgsize(ratios,
    #                                     "gen/img/performance_max_c.pdf",
    #                                     xlabel="Workgroup columns (\\% max)",
    #                                     figsize=figsize,
    #                                     color=sns.color_palette("Blues"))

    # ratios = [np.array(l) for l in
    #           json.load(open(fs.path(
    #               "~/data/msc-thesis/performance_r.json"
    #           )))]
    # visualise.performance_vs_max_wgsize(ratios,
    #                                     "gen/img/performance_max_r.pdf",
    #                                     xlabel="Workgroup rows (\\% max)",
    #                                     figsize=figsize,
    #                                     color=sns.color_palette("Reds"))

    # # Motivating example plots
    # motivating_examples(db)

    # # Ml Visualisations
    # figsize=(5.8,8)
    # # visualise.classification(db, "gen/img/classification-xval.pdf", job="xval",
    # #                          title="", figsize=figsize)
    # visualise.classification(db, "gen/img/classification-syn-real.pdf", job="synthetic_real",
    #                          title="", figsize=figsize)
    # visualise.classification(db, "gen/img/classification-arch.pdf", job="arch",
    #                          title="", figsize=figsize)
    # # visualise.classification(db, "gen/img/classification-kern.pdf", job="kern",
    # #                          title="", figsize=figsize)
    # # visualise.classification(db, "gen/img/classification-data.pdf", job="data",
    # #                          title="", figsize=figsize)

    # figsize=(2.7,9)
    # visualise.regression_classification(db, "gen/img/runtime-class-xval.pdf",
    #                                     figsize=figsize)

    # visualise.regression_classification(db, "gen/img/speedup-class-xval.pdf",
    #                                     table="speedup_classification_results",
    #                                     figsize=figsize)

    # # CLASSIFICATION ERROR HEATMAPS
    # for i,classifier in enumerate(db.classification_classifiers):
    #     classification_heatmaps(db, classifier, "xval",
    #                             "gen/img/heatmap_{}.pdf".format(i+1))
    # regression_heatmaps(db, "xval", "gen/img/reg_runtime_heatmap.pdf")
    # regression_heatmaps(db, "xval", "gen/img/reg_speedup_heatmap.pdf",
    #                     table="speedup_classification_results",
    #                     title="Speedup Regression")

    ml.stop()


if __name__ == "__main__":
    main()
