#!/usr/bin/env python2
from __future__ import division
from __future__ import print_function

import csv
import json
import re

import numpy as np
import matplotlib

# Use Agg backend to silence warnings on OS X.
matplotlib.use('Agg')

import matplotlib.pyplot as plt
import seaborn as sns

from matplotlib.ticker import FormatStrFormatter

import labm8 as lab
from labm8 import fs
from labm8 import io
from labm8 import latex
from labm8 import math as labmath
from labm8 import ml
from labm8 import system

import omnitune
from omnitune import skelcl
from omnitune.skelcl import db as _db
from omnitune.skelcl import unhash_params
from omnitune.skelcl import visualise
from omnitune.skelcl.dataset import Dataset
from omnitune.skelcl.migrate import migrate


def mktex(string, path):
    """
    Write a latex data file, appended by a comment sign.
    """
    system.echo("\\checkme{{{}}}%".format(string), path, end="")
    io.info("Wrote", path)


def print_params(params):
    wg_c, wg_r = unhash_params(params)
    return "${c} \\times {r}$".format(c=wg_c, r=wg_r)

def print_w(params):
    wg_c, wg_r = unhash_params(params)
    return "w_{{({c} \\times {r})}}".format(c=wg_c, r=wg_r)


#################
# Export tables #
#################
def create_hosts_table(output=None):
    output = output or "gen/tab/hosts.tex"
    reader = csv.reader(open("dat/hosts.csv"), delimiter="\t")
    header = reader.next()
    rows = [row for row in reader]
    latex.table(rows, output=output, columns=header, escape=False)

def create_stencil_runtime_components_table(output=None):
    output = output or "gen/tab/stencil-runtime-components.tex"
    reader = csv.reader(open("dat/stencil-runtime-components.csv"),
                        delimiter="\t")
    header = reader.next()
    rows = [row for row in reader]
    latex.table(rows, output=output, columns=header, escape=False)


def create_devices_table(db, output=None):
    def _escape_name(name):
        name = name.strip()
        name = re.sub("^\dx", "", name)
        name = re.sub("GeForce", "Nvidia", name)
        name = re.sub("Tahiti", "AMD Tahiti 7970", name)
        name = re.sub("Intel\(R\) Core\(TM\)", "Intel", name)
        name = re.sub(" CPU @ [0-9\.]+GHz", "", name)
        return name

    output = output or "gen/tab/devices.tex"
    infos = set()
    for row in db.execute("SELECT name,max_compute_units,"
                          "max_clock_frequency,local_mem_size,"
                          "global_mem_cache_size,global_mem_size "
                          "FROM devices WHERE id LIKE '1x%'"):
        name,cunits,freq,lmem,gcache,gmem = row
        infos.add((_escape_name(name),
                   cunits,
                   str(freq) + " Hz",
                   str(labmath.ceil(lmem / 1024)) + " KB",
                   str(labmath.ceil(gcache / 1024)) + " KB",
                   str(labmath.ceil(gmem / 1024 / 1024)) + " MB"))

    infos = list(sorted(infos, key=lambda x: x[0]))
    latex.table(infos, output=output, columns=(
        "Name",
        "Compute units",
        "Frequency",
        "Local Memory",
        "Global Cache",
        "Global Memory"
    ))


def create_kernels_table(db, output=None):
    def _process_row(row):
        def _process_kernel(kernel):
            north,south,east,west = db.execute("SELECT north,south,east,west "
                                               "FROM kernels WHERE id=?",
                                               (kernel,)).fetchone()
            instcount = db.execute("SELECT instruction_count FROM "
                                   "kernels where id=?",
                                   (kernel,)).fetchone()[0]
            return name, north, south, east, west, instcount

        name = row[0]
        kernels = db.execute("SELECT id from kernel_names where name=?", (name,)).fetchall()
        return [_process_kernel(row[0]) for row in kernels]

    output = output or "gen/tab/kernels.tex"
    synthetics, real = set(), set()
    for row in db.execute("SELECT DISTINCT name FROM kernel_names WHERE synthetic=1"):
        [synthetics.add(entry) for entry in _process_row(row)]
    for row in db.execute("SELECT DISTINCT name FROM kernel_names WHERE synthetic=0"):
        [real.add(entry) for entry in _process_row(row)]

    synthetics = list(sorted(synthetics, key=lambda x: x[0]))
    real = list(sorted(real, key=lambda x: x[0]))

    latex.table(synthetics + real, output=output, columns=(
        "Name",
        "North",
        "South",
        "East",
        "West",
        "Instruction Count"
    ))

def create_datasets_table(db, output=None):
    output = output or "gen/tab/datasets.tex"
    infos = set(row for row in
                db.execute("SELECT width,height,tin,tout "
                           "FROM datasets"))
    data = list(sorted(infos, key=lambda x: x[0]))
    latex.table(data, output=output, columns=(
        "Width",
        "Height",
        "Type in",
        "Type out"
    ))


def create_features_table(db, path):
    def _attribute_type(attribute):
        if attribute.type == 0:
            return "numeric"
        else:
            return "categorical: {}".format(attribute.num_values)

    def _format_name_col(name):
        return "\\texttt{{{}}}".format(latex.escape(name))

    def _table(rows, output):
        latex.table(rows, output=output, columns=("Name", "Type"),
                    escape=False, formatters=(_format_name_col, None))

    dataset = Dataset.load("~/data/msc-thesis/csv/oracle_params.csv", db)

    attributes = [[attribute.name, _attribute_type(attribute)]
                  for attribute in dataset.instances.attributes()]
    features = attributes[1:-1]
    half = labmath.ceil(len(features) / 2)

    _table(features[:half], fs.path(path, "features.1.tex"))
    _table(features[half:], fs.path(path, "features.2.tex"))


def create_results_tables(db):
    # Number of rows to include in tables.
    num_rows = 25

    output = "gen/tab/top_params_coverage.tex"
    data = [
        [row[0], round(row[1] * 100, 1), round(row[2] * 100, 1)] for row in
        db.execute(
            "SELECT params,coverage,performance "
            "FROM param_stats "
            "ORDER BY coverage DESC, performance DESC "
            "LIMIT ?",
            (num_rows,)
        )
    ]
    latex.table(data, output=output, columns=(
        "Parameter",
        "Legality (%)",
        "Performance (%)",
    ))

    output = "gen/tab/top_params_perf.tex"
    data = [
        [row[0], round(row[1] * 100, 1), round(row[2] * 100, 1)] for row in
        db.execute(
            "SELECT params,coverage,performance "
            "FROM param_stats "
            "ORDER BY performance DESC,coverage DESC "
            "LIMIT ?",
            (num_rows,)
        )
    ]
    latex.table(data, output=output, columns=(
        "Parameter",
        "Legality (%)",
        "Performance (%)",
    ))


def fine_grained_runtime_histograms():
    sample_runtimes = [
        np.array(l) for l in
        json.load(open(fs.path("~/data/msc-thesis/sample-runtimes.json")))
    ]

    # Found by hand:
    indicies = [
        601, # 2.0406245600000004
        895, # 25.012451818
        480, # 51.718092256000006
        590, # 75.140274775
        941, # 100.372847552
        939, # 100.9115374
        312, # 119.245880346
        437, # 143.98754486299998
        156, # 195.44022449400003
    ]

    for i,index in enumerate(indicies):
        runtimes = sample_runtimes[index]
        output = "gen/img/runtimes_histogram_{}.pdf".format(i+1)
        figsize=(2, 2)
        visualise.runtimes_histogram(runtimes, output=output, figsize=figsize)


def num_samples_vs_variance(db):
    data = json.load(open(fs.path("~/data/msc-thesis/ci.json")))
    figsize=(5.8, 2)

    min_samples = db.min_sample_count
    mean_samples = int(round(db.mean_samples))
    X, Y, _ = zip(*data)

    mktex(round(Y[X.index(min_samples)] * 100, 1), "gen/max_ci.tex")
    mktex(round(Y[X.index(mean_samples)] * 100, 1), "gen/mean_ci.tex")
    mktex(mean_samples, "gen/avg_sample_count.tex")

    output = "gen/img/ci_trend.pdf"
    visualise.confinterval_trend(X, Y, vlines=[min_samples, mean_samples],
                                 figsize=figsize, output=output)


def main():
    ml.start()
    db = migrate(_db.Database("/usr/share/omnitune/db/skelcl.db"))

    fs.rm("gen")
    fs.mkdir("gen/img")
    fs.mkdir("gen/tab")

    # Set plot style.
    sns.set_context("notebook", font_scale=.8, rc={"lines.linewidth": 2})
    sns.set_style("whitegrid")

    ##################
    # Dynamic values #
    ##################
    param_counts = db.num_params_for_scenarios().values()
    mktex(int(round(labmath.mean(param_counts))), "gen/num_avg_params.tex")
    mktex(max(param_counts), "gen/num_max_params.tex")

    one_r = db.one_r()
    mktex(print_params(one_r[0]), "gen/one_r.tex")
    mktex(round(one_r[2], 2), "gen/one_r_perf.tex")
    mktex(int(round(one_r[2] * 100)), "gen/baseline_perf_perc.tex")

    mktex(db.num_rows("runtime_stats"), "gen/num_runtime_stats.tex")
    mktex(db.num_rows("runtimes"), "gen/num_samples.tex")
    mktex(db.num_rows("scenarios"), "gen/num_scenarios.tex")
    mktex(db.min_sample_count, "gen/min_sample_count.tex")
    mktex(db.max_sample_count, "gen/max_sample_count.tex")
    mktex(db.execute("SELECT Max(num_samples) FROM runtime_stats").fetchone()[0],
          "gen/max_sample_count.tex")
    mktex(len(db.real_kernels), "gen/num_real_kernels.tex")

    wg_c = [str(row[0]) for row in
            db.execute("SELECT DISTINCT wg_c FROM params order by wg_c asc")]
    wg_r = [str(row[0]) for row in
            db.execute("SELECT DISTINCT wg_r FROM params order by wg_r asc")]
    mktex(", ".join(wg_c), "gen/wg_c.tex")
    mktex(", ".join(wg_r), "gen/wg_r.tex")
    mktex(len(wg_c) * len(wg_r), "gen/num_params.tex")

    # Oracle param frequencies
    oracle_params = sorted(db.oracle_param_frequencies(normalise=True).items(),
                           reverse=True, key=lambda x: x[1])
    freqs = [x[1] for x in oracle_params]

    acc = 0
    acc_freqs = []
    for i,freq in enumerate(freqs):
        acc += freq
        acc_freqs.append(acc)
        if acc > .5:
            mktex(i + 1, "gen/num_wgsizes_50_accuracy.tex")
            break
    max_oracle_param = oracle_params[0]
    mktex(print_params(max_oracle_param[0]),
          "gen/max_oracle_param.tex")
    mktex(print_w(max_oracle_param[0]),
          "gen/max_oracle_param_w.tex")
    mktex("${}\\%$".format(int(round(max_oracle_param[1] * 100))),
          "gen/max_oracle_param_frequency.tex")

    # Max speedups
    max_speedups = sorted(db.max_speedups().values(), reverse=True)
    mktex(round(max_speedups[0], 1),
          "gen/max_possible_speedup.tex")
    mktex(int(round((1 - 1 / max_speedups[0]) * 100)),
          "gen/max_possible_speedup_perc.tex")
    mktex(round(max_speedups[-1], 1),
          "gen/min_possible_speedup.tex")
    mktex(int(round((1 - 1 / max_speedups[-1]) * 100)),
          "gen/min_possible_speedup_perc.tex")
    mean_possible_speedup = labmath.geomean(max_speedups)
    mktex(round(mean_possible_speedup, 1),
          "gen/avg_possible_speedup.tex")
    mktex(int(round((1 - 1 / mean_possible_speedup) * 100)),
          "gen/avg_possible_speedup_perc.tex")

    # ML speedups
    best_classification_results = db.best_classification_results
    best_synthetic_real_classification_results = db.best_synthetic_real_classification_results
    mktex(int(round(best_classification_results[2])),
          "gen/best_avg_classification_performance.tex")
    mktex(round(best_classification_results[3], 2),
          "gen/best_avg_classification_speedup.tex")
    mktex(round(best_classification_results[4], 2),
          "gen/best_max_classification_speedup.tex")

    # TODO: *actual* human expert.
    mktex(int(round(best_classification_results[5] * 100) - 100),
          "gen/best_avg_classification_speedup_he_perc.tex")

    mktex(int(round(best_synthetic_real_classification_results[2])),
          "gen/best_avg_synthetic_real_classification_performance.tex")
    mktex(round(best_synthetic_real_classification_results[3], 2),
          "gen/best_avg_synthetic_real_classification_speedup.tex")
    mktex(int(round(db.biggest_synthetic_real_classification_performance_drop)),
          "gen/biggest_synthetic_real_classification_performance_drop.tex")

    # Tables.
    create_hosts_table()
    create_stencil_runtime_components_table()
    create_devices_table(db)
    create_kernels_table(db)
    create_datasets_table(db)
    create_features_table(db, "gen/tab/")
    create_results_tables(db)

    ################
    # Export plots #
    ################

    # Variance trends
    num_samples_vs_variance(db)

    # Runtime histograms
    fine_grained_runtime_histograms()

    # Heatmaps
    figsize=(3.28, 2.7)
    visualise.oracle_wgsizes(db, "gen/img/oracle_param_space.pdf",
                             figsize=figsize, cmap="Reds", title=None,
                             vmax=0.10 # clamp range
    )
    visualise.max_wgsizes(db, "gen/img/max_wgsizes.pdf",
                          figsize=figsize, cmap="Blues", title=None)

    figsize=(2.75, 2)
    visualise.num_samples(db, "gen/img/num_samples.pdf", title="",
                          figsize=figsize)
    visualise.num_params(db, "gen/img/num_params.pdf", title="",
                         figsize=figsize)

    # Trend plots
    figsize=(5.8,2)
    visualise.oracle_speedups(db, "gen/img/oracle_speedups.pdf", title="",
                              figsize=figsize)
    visualise.max_speedups(db, "gen/img/max_speedups.pdf", title="",
                           figsize=figsize)
    visualise.num_params_vs_accuracy(db, "gen/img/num_params_oracle.pdf",
                                     title="", figsize=figsize)
    visualise.performance_vs_coverage(db, "gen/img/params_summary.pdf",
                                      title="", figsize=figsize)

    # Boxplots grouped by kernel,device,dataset
    figsize=(5.8,3) # Full page width
    visualise.kernel_performance(db, "gen/img/performance_kernels.pdf",
                                 title="", figsize=figsize)
    figsize=(5.8/2,3) # Half-width
    visualise.device_performance(db, "gen/img/performance_devices.pdf",
                                 title="", figsize=figsize)
    visualise.dataset_performance(db, "gen/img/performance_datasets.pdf",
                                  title="", figsize=figsize)

    # Boxplots grouped by wgsize
    figsize=(5.8,3)
    ratios = [np.array(l) for l in
              json.load(open(fs.path(
                  "~/data/msc-thesis/performance_wgsize.json"
              )))]
    visualise.performance_vs_max_wgsize(ratios,
                                        "gen/img/performance_max_wgsize.pdf",
                                        xlabel="Workgroup size (% max)",
                                        figsize=figsize)

    figsize=(5.8/2,3) # Half-width
    ratios = [np.array(l) for l in
              json.load(open(fs.path(
                  "~/data/msc-thesis/performance_c.json"
              )))]
    visualise.performance_vs_max_wgsize(ratios,
                                        "gen/img/performance_max_c.pdf",
                                        xlabel="Workgroup columns (% max size)",
                                        figsize=figsize)

    ratios = [np.array(l) for l in
              json.load(open(fs.path(
                  "~/data/msc-thesis/performance_r.json"
              )))]
    visualise.performance_vs_max_wgsize(ratios,
                                        "gen/img/performance_max_r.pdf",
                                        xlabel="Workgroup rows (% max size)",
                                        figsize=figsize)

    # Ml Visualisations
    figsize=(5.8,4)
    visualise.classification(db, "gen/img/classification-xval.pdf", job="xval",
                             title="", figsize=figsize)
    visualise.runtime_regression(db, "gen/img/runtime-regression-xval.pdf",
                                 job="xval", title="", figsize=figsize)
    visualise.err_fn_speedups(db, "random_fn",
                              "gen/img/classification-xval-random.pdf",
                              job="xval", sort=True, title="", figsize=figsize)

    ml.stop()


if __name__ == "__main__":
    main()
