The rapid transition towards multicore hardware has left application
programmers requiring higher-level abstractions for coping with the
complexity of parallel programming. Algorithmic Skeletons provide such
abstractions but, without extensive tuning, typically cannot compete
with the performance of hand optimised code. This paper proposes
developing a dynamic, ``always-on'' autotuner for SkelCL, an
Algorithmic Skeleton library which enables high-level programming of
multi-GPU systems. An online machine learning system will be used to
create a feedback loop of constant testing and evaluation of skeleton
parameters across the lifespan of programs. It will use dynamic
features extracted from muscle functions and input data to maximise
runtime performance. Such a system will extend the state of the art by
enabling empirical optimisation without the huge offline training
phases associated with iterative compilation.
