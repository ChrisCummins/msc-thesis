\TODO{Challenges of parallel programming.}

\section{Parallel Programming with Algorithmic Skeletons}

\TODO{Intro to alg skel}

% Cole, M. I. (1989). Algorithmic Skeletons: Structured Management of
% Parallel Computation. Pitman London. Retrieved from
% http://homepages.inf.ed.ac.uk/mic/Pubs/skeletonbook.pdf
\TODO{Murray's thesis~\cite{Cole1989}.}

% Cole, M. I. (2004). Bringing skeletons out of the closet: a
% pragmatic manifesto for skeletal parallel programming. Parallel
% Computing, 30(3), 389–406. doi:10.1016/j.parco.2003.12.002
\TODO{Algorithmic Skeletons in academia~\cite{Cole2004}.}

% Striegnitz, J. (2000). Making C ++ Ready for Algorithmic Skeletons
% (Vol. 2000). Retrieved from http://www.fz-juelich.de/zam/FACT
\TODO{Early work towards C++ Alg. Skeletons\cite{Striegnitz2000}}

\subsection{Abstracting Task and Data Parallelism}

\TODO{Short examples of task parallel skeletons. Describe the
  shortcomings of GPUs for task parallel operations. Don't repeat
  myself from the data parallel operations defined in the SkelCL
  intro.}

\subsection{Algorithmic Skeleton Frameworks}

\TODO{Case studies of skeleton-esque products in industry: Intel
  Thread Building Blocks, and Google's MapReduce and the various
  implementations. Comment on their lack of ``Skeleton'' branding.}


\section{Heterogeneous parallelism and GPUs}

\TODO{Start with a description of GPU hardware, i.e. SIMD EUs, many
  simple cores, lockstep execution. Describe the historical reasoning
  for this and how it influences the types of programs which are well
  suited for GPUs. GPUs offer huge throughput, but are even more
  challenging to program and debug. Give concrete examples.}

% S. Ryoo, C. I. Rodrigues, S. S. Baghsorkhi, S. S. Stone, D. B. Kirk,
% and W. W. Hwu, “Optimization principles and application performance
% evaluation of a multithreaded GPU using CUDA,” Proc. 13th ACM
% SIGPLAN Symp. Princ. Pract. parallel Program. - PPoPP ’08, p. 73,
% 2008.
\TODO{The challenges and approaches to optimising GPU programs. CUDA
programming requires the developer to explicitly manage data layout in
DRAM, caching, thread communication and other resources. Performance
of such programs depends heavily on fully utilizing zero-overhead
thread scheduling, memory bandwidth, thread grouping, shared control
flow, and intra-block thread communication. The paper gives an example
of optimising matrix multiplication by utilising shared memory through
tiling, and loop unrolling. \cite{Ryoo2008a}}

Prior research has shown that the performance of a GPGPU program is
heavily influenced by proper exploitation of local shared memory and
synchronisation costs~\cite{Ryoo2008a, Lee2010} \TODO{``Where's the
  data?'' paper}

% S. Ryoo, C. I. Rodrigues, S. S. Stone, S. S. Baghsorkhi, S.-Z. Ueng,
% J. a. Stratton, and W. W. Hwu, “Program optimization space pruning
% for a multithreaded GPU,” in Proceedings of the 6th annual IEEE/ACM
% international symposium on Code generation and optimization, 2008,
% pp. 195–204.
\TODO{Background info about optimizing for GPUs, including a checklist
of optimization metrics: \cite{Ryoo2008}}

% D. Grewe, Z. Wang, and M. F. P. M. O’Boyle, “Portable mapping of
% data parallel programs to OpenCL for heterogeneous systems,” in Code
% Generation and Optimization (CGO), 2013 IEEE/ACM International
% Symposium on, 2013, pp. 1–10.
\TODO{Vaguely ``autopar''-esque: automatic translation from OpenMP to
  OpenCL~\cite{Grewe2013}.}


\subsubsection{GPU vs CPU performance analysis}

% V. W. Lee, P. Hammarlund, R. Singhal, P. Dubey, C. Kim, J. Chhugani,
% M. Deisher, D. Kim, A. D. Nguyen, N. Satish, M. Smelyanskiy, and
% S. Chennupaty, “Debunking the 100X GPU vs. CPU myth,” ACM SIGARCH
% Comput. Archit. News, vol. 38, p. 451, 2010.
In~\cite{Lee2010}, \citeauthor{Lee2010} present a performance analysis
of optimised throughput computing applications for GPUs and CPUs. Of
the 14 applications tested, they found GPU performance to be
$0.7\times$-$14.9\times$ that of multi-threaded CPU code, with an
average of only 2.5$\times$. This is much lower than the
$100\times$-$1000\times$ values reported by other studies,
% TODO: ^^ Citation needed!
a fact that they attribute to uneven comparison of optimised GPU code
to unoptimised CPU code, or vice versa. \citeauthor{Lee2010} found
that multithreading, cache blocking, reordering of memory accesses and
use of SIMD instructions to contribute most to CPU performance. For
GPUs, the most effective optimisations are reducing synchronization
costs, and exploiting local shared memory. In all cases, the programs
were optimised and hand-tuned by programmers with expert knowledge of
the target architectures. It is unclear whether their performance
results still hold for subsequent generations of devices.


\subsection{GPGPU Programming}

\TODO{Introduction to popular GPU programming models: OpenCL and
  CUDA.}

% K. Komatsu, K. Sato, Y. Arai, K. Koyama, H. Takizawa, and
% H. Kobayashi, “Evaluating performance and portability of OpenCL
% programs,” in The fifth international workshop on automatic
% performance tuning, 2010, p. 7.
\citeauthor{Komatsu2010} provide quantitative comparisons between the
performance of CUDA and OpenCL kernels
in~\cite{Komatsu2010}. \TODO{This paper is deserving of close
  scrutiny, as they perform an in-depth evaluation of the effect of
  workgroup size on the performance of kernels across devices and
  programs.}

% J. Fang, A. L. Varbanescu, and H. Sips, “A Comprehensive Performance
% Comparison of CUDA and OpenCL,” in Parallel Processing (ICPP), 2011
% International Conference on, 2011, pp. 216–225.
\TODO{Comparing OpenCL and CUDA performance: \cite{Karimi2010}}

% Enmyren, J., & Kessler, C. (2010). SkePU: a multi-backend skeleton
% programming library for multi-GPU systems. In Proceedings of the
% fourth international workshop on High-level parallel programming and
% applications (pp. 5–14). ACM. Retrieved from
% http://dl.acm.org/citation.cfm?id=1863487
\paragraph{SkePU} \TODO{Similar to SkelCL in scope and ambition,
  alternative implementation with C++ macros and
  CUDA~\cite{Enmyren2010}.}

\subsection{The OpenCL Programming Model}

\TODO{Technical details of OpenCL model. Describe the memory model.}


% Rul, S., Vandierendonck, H., Haene, J. D., & Bosschere,
% K. De. (2010). An Experimental Study on Performance Portability of
% OpenCL Kernels. In 2010 Symposium on Application Accelerators in
% High Performance Computing (SAAHPC’10) (pp. 4–6).
\TODO{Portability of OpenCL kernels: \cite{Rul2010}}

\subsubsection{Problem decomposition and workgroups}

In OpenCL, kernels are mapped to work-items for execution on the
processing units of GPUs and CPUs. These work-items are then grouped
into one or more workgroups. The choice of workgroup size is left to
the developer, but with two sets of constraints. The first set of
constraints is the maximum workgroup size which an execution device
supports. This value cannot be exceeded, irrespective of the kernel
being executed. The second constraint is the maximum workgroup size a
kernel supports, and can only be queried at runtime once a kernel has
been compiled. The selection of workgroup size for stencil skeletons
is particularly relevant to the performance of the stencil as it
affects utilisation of fast local memory. In a stencil code, each
work-item reads the values of multiple neighbouring elements. To
facilitate this, the value of all elements within a workgroup are
stored in fast local memory, which greatly reduces the read latency
for GPUs. Changing the workgroup size affects the amount of local
memory required for each workgroup, which in turn affects the number
of workgroups which may be simultaneously active.


\section{High-Level GPU Programming with SkelCL}

SkelCL\footnote{\url{http://skelcl.uni-muenster.de}} is an object
oriented C++ library that provides OpenCL implementations of data
parallel algorithmic skeletons for heterogeneous
parallelism. Skeletons are parameterised with muscle functions by the
user, which are compiled into OpenCL kernels for execution on device
hardware. The Vector and Matrix container types transparently handle
communication between the host and device memory, and support
partitioning for multi-GPU execution.

% Steuwer, M., Kegel, P., & Gorlatch, S. (2011). SkelCL - A Portable
% Skeleton Library for High-Level GPU Programming. In Parallel and
% Distributed Processing Workshops and Phd Forum (IPDPSW), 2011 IEEE
% International Symposium on
% (pp. 1176–1182). IEEE. doi:10.1109/IPDPS.2011.269
\TODO{The introductory SkelCL paper. Most highly cited:
\cite{Steuwer2011}}

% Steuwer, M., & Gorlatch, S. (2013). SkelCL: Enhancing OpenCL for
% High-Level Programming of Multi-GPU Systems. Parallel Computing
% Technologies, 7979, 258–272. doi:10.1007/978-3-642-39958-9_24
\TODO{Support for multi-GPU systems: \cite{Steuwer2013a}}

% S. Breuer, M. Steuwer, and S. Gorlatch, “Extending the SkelCL
% Skeleton Library for Stencil Computations on Multi-GPU Systems,”
% HiStencils 2014, pp. 23–30, 2014.
\TODO{Stencil computations: \cite{Breuer2014}}

% M. Steuwer, M. Friese, S. Albers, and S. Gorlatch, “Introducing and
% implementing the allpairs skeleton for programming multi-GPU
% Systems,” Int. J. Parallel Program., vol. 42, pp. 601–618, 2014.
\TODO{Allpairs skeleton: \cite{Steuwer2014}}


% Steuwer, M., & Gorlatch, S. (2013). High-level Programming for
% Medical Imaging on Multi-GPU Systems Using the SkelCL
% Library. Procedia Computer Science, 18,
% 749–758. doi:10.1016/j.procs.2013.05.239
\TODO{An example of reduced programmer effort for real world
application using SkelCL: \cite{Steuwer2013}}

% Steuwer, M., Kegel, P., & Gorlatch, S. (2012). Towards High-Level
% Programming of Multi-GPU Systems Using the SkelCL Library. In
% Parallel and Distributed Processing Symposium Workshops & PhD Forum
% (IPDPSW), 2012 IEEE 26th International
% (pp. 1858–1865). Ieee. doi:10.1109/IPDPSW.2012.229
\TODO{\cite{Steuwer2012}}

\subsection{Pattern definitions}

\paragraph{Map}

\begin{equation}
\map\left(f, [x_1,x_2,\ldots,x_n]\right) \to [f(x_1),f(x_2),\ldots,f(x_n)]
\end{equation}

When applied to an $n \times m$ matrix:

\begin{equation}
\map\left(f,
\begin{bmatrix}
  x_{11} & \cdots & x_{1m} \\
  \vdots & \ddots & \vdots \\
  x_{n1} & \cdots & x_{nm}
\end{bmatrix}\right)
\to
\begin{bmatrix}
  f(x_{11}) & \cdots & f(x_{1m}) \\
  \vdots & \ddots & \vdots \\
  f(x_{n1}) & \cdots & f(x_{nm})
\end{bmatrix}
\end{equation}

\paragraph{Zip}

\begin{equation}
\zip\left( \oplus, [x_1,x_2,\ldots,x_n], [y_1,y_2,\ldots,y_n] \right)
\to
\left[ x_1 \oplus y_1, x_2 \oplus y_2, \ldots, x_n \oplus y_n \right]
\end{equation}

\begin{equation}
\begin{split}
\zip \left( \oplus,
\begin{bmatrix}
  x_{11} & \cdots & x_{1m} \\
  \vdots & \ddots & \vdots \\
  x_{n1} & \cdots & x_{nm}
\end{bmatrix},
\begin{bmatrix}
  y_{11} & \cdots & y_{1m} \\
  \vdots & \ddots & \vdots \\
  y_{n1} & \cdots & y_{nm}
\end{bmatrix} \right) \\
\to
\begin{bmatrix}
  x_{11} \oplus y_{11} & \cdots & x_{1m} \oplus y_{1m} \\
  \vdots & \ddots & \vdots \\
  x_{n1} \oplus y_{n1} & \cdots & x_{nm} \oplus y_{nm}
\end{bmatrix}
\end{split}
\end{equation}

\paragraph{Reduce}

\begin{equation}
\reduce \left( \oplus, i, [x_1,x_2,\ldots,x_n] \right)
\to
x_1 \oplus x_2 \oplus \ldots \oplus x_n
\end{equation}

\begin{equation}
\reduce \left( \oplus, i,
\begin{bmatrix}
  x_{11} & \cdots & x_{1m} \\
  \vdots & \ddots & \vdots \\
  x_{n1} & \cdots & x_{nm}
\end{bmatrix} \right)
\to
x_{11} \oplus x_{12} \oplus \ldots \oplus x_{nm}
\end{equation}

\paragraph{Scan}

\begin{equation}
\scan \left( \oplus, i, [x_1,x_2,\ldots,x_n] \right)
\to
\left[ i, x_1, x_1 \oplus x_2, \ldots, x_1 \oplus x_2 \oplus \ldots \oplus x_n \right]
\end{equation}

\paragraph{AllPairs}

\begin{equation}
\allpairs \left( \oplus,
\begin{bmatrix}
  x_{11} & \cdots & x_{1d} \\
  \vdots & \ddots & \vdots \\
  x_{n1} & \cdots & x_{nd}
\end{bmatrix},
\begin{bmatrix}
  y_{11} & \cdots & y_{1m} \\
  \vdots & \ddots & \vdots \\
  y_{n1} & \cdots & y_{nm}
\end{bmatrix} \right)
\to
\begin{bmatrix}
  z_{11} & \cdots & z_{1m} \\
  \vdots & \ddots & \vdots \\
  z_{n1} & \cdots & z_{nm}
\end{bmatrix}
\end{equation}

where:

\begin{equation}
z_{ij} =
\left[ x_{i1}, x_{i2}, \ldots, x_{id} \right] \oplus
\left[ y_{j1}, y_{j2}, \ldots, y_{jd} \right]
\end{equation}

an additional implementation is provided for when the $\oplus$
operator is known to match that of a zip pattern:

\begin{equation}
z_{ij} =
\left[
  x_{i1}, \oplus y_{j1}, x_{i2} \oplus y_{j2}, \ldots, x_{id} \oplus y_{jd}
\right]
\end{equation}


\paragraph{Stencil}

Given a customising function $f$, a \emph{stencil shape} $S$

\begin{equation}
\stencil \left( f, S,
\begin{bmatrix}
  x_{11} & \cdots & x_{1m} \\
  \vdots & \ddots & \vdots \\
  x_{n1} & \cdots & x_{nm}
\end{bmatrix} \right)
\to
\begin{bmatrix}
  z_{11} & \cdots & z_{1m} \\
  \vdots & \ddots & \vdots \\
  z_{n1} & \cdots & z_{nm}
\end{bmatrix}
\end{equation}

where:

\begin{equation}
z_{ij} = f \left(
\begin{bmatrix}
  z_{i-S_n,j-S_w} & \cdots & z_{i-S_n,j+S_e} \\
  \vdots & \ddots & \vdots \\
  z_{i+S_s,j-S_w} & \cdots & z_{i+S_s,j+S_e}
\end{bmatrix} \right)
\end{equation}

A popular application of Stencil codes is for iterative problems, in
which \todo{\ldots} discrete time steps $0 <= t <= t_{max}$, and
$t \in \mathbb{Z}$

\begin{equation}
g(f, S, M, t) =
\begin{cases}
  \stencil \left( f, S, g(f, S, M, t-1) \right),& \text{if } t \geq 1\\
  M_{init}, & \text{otherwise}
\end{cases}
\end{equation}


\subsection{Container Types}

\TODO{Description of vector and matrices, supported data types, lazy
  data transfer \ldots}

\subsubsection{Data distributions}

\TODO{Description and diagrams for single, block, copy, and overlap
  distributions.}


\subsection{Implementation Details}

Each skeleton is represented by a template class, declared in a header
file detailing the public API. A private header file contains the
template definition. E.g. \texttt{SkelCL/Map.h} contains the Map
class, and \texttt{SkelCL/detail/MapDef.h} contains the
implementation. Non-trivial kernels are stored in separate source
files, e.g. \texttt{SkelCL/detail/MapKernel.cl}.

\TODO{Description of OpenCL skeleton templates, and the compilation
  process - i.e. substitution of user functions, handling additional
  arguments  \ldots}

\TODO{Algorithm listing for stencil}

\subsection{Example Applications}

\TODO{%
  Provide definition of three simple example programs, then code
  listings for SkelCL implementations and a comparison of runtimes
  using a decent GPU vs. sequential CPU. Preferably also hand coded
  OpenCL?%
}

\subsubsection{Application 1: Dot Product}

\TODO{Definition, and performance results.}

\lstset{language=C++}
\begin{lstlisting}[
  basicstyle=\scriptsize,
  caption={Example program to calculate dot product using SkelCL.}
]
#include <SkelCL/SkelCL.h>
#include <SkelCL/Vector.h>
#include <SkelCL/Zip.h>
#include <SkelCL/Reduce.h>

int main(int argc, char* argv[]) {
  // Initialise SkelCL to use any device.
  skelcl::init(skelcl::nDevices(1).deviceType(skelcl::device_type::ANY));

  // Define the skeleton objects.
  skelcl::Zip<int(int, int)> mult("int func(int x, int y) { return x * y; }");
  skelcl::Reduce<int(int)> sum("int func(int x, int y) { return x + y; }", "0");

  // Create two vectors A and B of length "n".
  const int n = 1024; skelcl::Vector<int> A(n), B(n);
  skelcl::Vector<int>::iterator a = A.begin(), b = B.begin();
  while (a != A.end()) { *a = rand() % n; ++a; *b = rand() % n; ++b; }

  // Invoke skeleton: x = A . B
  int x = sum(mult(A, B)).first();

  return 0;
}
\end{lstlisting}

\subsubsection{Application 2: Mandelbrot Set}

\TODO{Definition, listing, and performance results.}

\subsubsection{Application 3: Gaussian Blur}

\TODO{Definition, listing, and performance results.}

\subsection{Grid Decomposition of Stencil Codes}

\TODO{Add diagram showing workgroup decomposition.}
