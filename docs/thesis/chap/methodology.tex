\section{Introduction}

This chapter describes an exhaustive enumeration of the workgroup size
optimisation space for \input{gen/num_scenarios} combinations of
architecture, program, and dataset. It contains the methodology used
to achieve statistically sound comparisons of competing programs using
different configurations, and the steps necessary to obtain repeatable
results.


\section{Experimental Setup}

\begin{table}
\input{tab/hosts}
\caption{%
  Specification of experimental platforms.%
}
\label{tab:hosts}
\end{table}

Table~\ref{tab:hosts} describes the experimental platforms used.  All
runtimes were recorded with millisecond precision using either the
system clock or OpenCL's Profiling API. Measurement noise was
minimised by reducing system load through disabling all unwanted
services and graphical environments, and exclusive single-user access
was ensured for each platform. Frequency governors for each CPU were
disabled, and the benchmark processes were set to the highest priority
available to the task scheduler. Datasets and programs were stored in
an in-memory file system.

\subsection{Devices}

\begin{table}
\input{tab/devices}
\caption{%
  Specification of experimental OpenCL devices.%
}
\label{tab:hw}
\end{table}

Table~\ref{tab:hw} describes the OpenCL devices used for testing, as
available on the experimental platforms.

\subsection{Benchmark Applications}

In addition to the synthetic stencil benchmarks described in
Section~\ref{sec:training}, five reference implementations of standard
stencil applications from the fields of image processing, cellular
automata, and partial differential equation solvers are used:

% \begin{table}
% \footnotesize
% \centering
% \begin{tabular}{| l | l | l | l | l |}
% \hline
% \textbf{Name} & \textbf{Application} & \textbf{Skeletons used} & \textbf{Iterative?} & \textbf{LOC}\\
% \hline
% CannyEdgeDetection & Image processing & Stencil & - & 225 / 61\\
% DotProduct & Linear algebra & Zip, Reduce & - & 143 / 2\\
% FDTD & Scientific simulation & Map, Stencil & Y & 375 / 127\\
% GameOfLife & Cellular automata & Stencil & Y & 92 / 12\\
% GaussianBlur & Image processing & Stencil & - & 262 / 47\\
% HeatSimulation & Scientific simulation & Stencil & Y & 180 / 13\\
% MandelbrotSet & Fractal computation & Map & Y & 133 / 78\\
% MatrixMultiply & Linear algebra & AllPairs & - & 267 / 8\\
% SAXPY & Linear algebra & Zip & - & 149 / 3\\
% \hline
% \end{tabular}
% \caption{Benchmark applications. The LOC column shows lines of code, split between host (C++) and device (OpenCL).}
% \label{tab:benchmarks}
% \end{table}

\TODO{Descriptions (with diagrams) for each application:}

\begin{itemize}
\item \textbf{Finite Difference Time Domain}
\item \textbf{Heat Equation}
\item \textbf{Gaussian Blur} \TODO{Reword this to be more clear} The
  Gaussian blur is a common image processing algorithm, used to reduce
  noise and detail in an image. A two dimensional Gaussian blur
  defines a function to compute a pixel value $f(x,y)$ using a
  standard deviation $\sigma$ using:
  %
  \begin{equation}
    f(x,y) = \frac{1}{2\pi\sigma^2}e^{-\frac{x^2 + y^2}{2\sigma^2}}
  \end{equation}
  %
  Gaussian blurs are parameterised by a radius $r$ which define
  symmetric, square stencil regions about the centre
  pixel. \TODO{Describe the range of blur radius' used.} Unlike the
  previous two applications, the Gaussian blur is not an iterative
  stencil.
\item \textbf{Game of Life} Conway's Game of Life~\cite{Conway1970} is
  a cellular automaton which models the evolution of a regular grid of
  cells over discrete time steps. At each time step, each cell value
  is updated to be either \emph{live} or \emph{dead} based on it's
  current value and the value of the nearest neighbouring elements
  (Algorithm~\ref{alg:gol}). The stencil shape for Game of Life is
  always 1 in each direction.
\item \textbf{Canny Edge Detection} The Canny edge detection algorithm
  consists of four distinct stages: \TODO{4 separate stencils, with
    different behaviours.}
\end{itemize}

\begin{algorithm}[b]
\caption{Conway's Game of Life}
\label{alg:gol}
\input{alg/gol}
\end{algorithm}

\begin{table}
\input{tab/kernels}
\caption{%
  Stencil kernels, border sizes (north, south, east, and west),
  and static instruction counts. \FIXME{Tidy up the duplicate entries\ldots}
}
\label{tab:kernels}
\end{table}

Table~\ref{tab:kernels} shows the details of the stencils kernels for
these reference implementations, and the synthetic training benchmarks
used.


\subsection{Datasets}

For each benchmark, multiple dataset sizes were used, as shown in
table~\ref{tab:datasets}.

\begin{table}
\input{tab/datasets}
\caption{%
  Datasets used.%
}
\label{tab:datasets}
\end{table}


\subsection{Sampling Strategy}\label{sec:sampling}

The number of ``moving parts'' in the modern software stack provides
multiple sources of noise when measuring program execution times. As
such, evaluating the relative performance of different versions of
programs requires a judicious approach to isolate the appropriate
performance metrics and to take a statistically rigorous approach to
collecting data.

\subsubsection{Isolating the Impact of Workgroup Size}

\begin{table}
\include{tab/stencil-runtime-components}
\caption{Execution phases of a SkelCL stencil skeleton. ``Fixed''
  costs are those which occur up to once per stencil
  invocation. ``Iterative'' costs are those which scale with the
  number of iterations of a stencil.}
\label{tab:stencil-runtime-components}
\end{table}

The execution of a SkelCL stencil application can be divided into 6
distinct phases, shown in Table~\ref{tab:stencil-runtime-components}.

\begin{itemize}
\item \textbf{Kernel compilation times} Upon invocation, template
  substitution is performed of the user code into the stencil skeleton
  implementation, then compiled into an OpenCL program. Once compiled,
  the program binary is cached for the lifetime of the host program.
\item \textbf{Skeleton prepare times} Before a kernel is executed, a
  preparation phase is required to allocate buffers for the input and
  output data on each execution device.
\item \textbf{Host $\rightarrow$ Device and Device $\rightarrow$ Host
    transfers} Data must be copied to and from the execution devices
  before and after execution of the stencils, respectively. Note that
  this is performed lazily, so iterative stencils do not require
  repeated transfers between host and device memory.
\item \textbf{Kernel execution times} This is the time elapsed
  executing the stencil kernel, and is representative of ``work
  done''.
\item \textbf{Devices $\leftrightarrow$ Host (sync) transfers} For
  iterative stencils on multiple execution devices, an overlapping
  halo region is shared at the border between the devices' grids. This
  must be synchronised between iterations, requiring an intermediate
  transfer to host memory, since device to device memory is not
  currently supported by OpenCL.
\end{itemize}

For each of the six distinct phases of execution, accurate runtime
information can be gathered either through timers embedded in the host
code, or using the OpenCL \texttt{clGetEventProfilingInfo()} API for
operations on the execution devices. For single-device stencils, the
total time $t$ of a SkelCL stencil application is simply the sum of
all times recorded for each distinct phase:
%
\begin{equation}
t = \bm{1c} + \bm{1p} + \bm{1u} + \bm{1k} + \bm{1d}
\end{equation}
%
Note that there are no synchronisation costs $s$. For applications
with $n$ execution devices, the runtime can be approximate as the sum
of the sequential host-side phases, and the sum of the device-side
phases divided by the number of devices:
%
\begin{equation}
t \approx \sum_{i=1}^n{(\bm{1c}_{i})} + \bm{1p} + \bm{1s} +
  \frac{\sum_{i=1}^n{\bm{1u}_{i} + \bm{1k}_{i} + \bm{1d}_{i}}}{n}
\end{equation}
%
The purpose of tuning workgroup size is to maximise the throughput of
stencil kernels. For this reason, isolating the kernel execution times
$\bm{k}$ produces the most accurate performance comparisons, as it
removes the impact of constant overheads introduced by memory
transfers between host and device memory, for which the selection of
workgroup size has no influence. Note that as demonstrated
in~\cite{Gregg2011}, care must be taken to ensure that isolating
device compute time does not cause misleading comparisons to be made
between devices. For example, if using an autotuner to determine
whether execution of a given stencil is faster on a CPU or GPU, the
device transfer times $\bm{u}$, $\bm{d}$, and $\bm{s}$ would need to
be considered. For our purposes, we do not need to consider the
location of the data in the system's memory as it is has no bearing on
the execution time of a stencil kernel.


\subsubsection{Validating Program Behaviour}

\TODO{Checking output against gold standard from $W_{safe}$}


\section{Summary}

This section describes the methodology for collecting relative
performance data of SkelCL stencil benchmarks under different
combinations of architecture, program, dataset, and workgroup size.
