GPUs enable massive performance through heterogeneous
parallelism. However, developing software for these devices is
challenging, as the programming models provided by OpenCL and CUDA
require a low level knowledge of the underlying architecture to
properly exploit the potential performance. SkelCL addresses this
programmability challenge by providing high level skeleton patterns
for common data parallel operations. This project demonstrates that
the parameters which are necessarily abstracted by such skeletons can
have a huge impact on performance. To demonstrate this, I present an
autotuner for selecting the \emph{workgroup size} of Stencil pattern
kernels.

% B. Catanzaro and K. Keutzer, “Parallel computing with patterns and
% frameworks,” XRDS Crossroads, ACM Mag. Students, vol. 17, no. 5,
% p. 22, 2010.
\todo{\cite{Catanzaro2010}}

\TODO{The rationale for autotuning long running iterative skeleton
  applications is that the longer the program runs, the smaller the
  training data we can reasonably expect the user to gather. A typical
  long running scientific program workload will only be run once, as
  there is no need to repeat a computation for which you already have
  the answer.}

\TODO{There is already a wealth of research literature on the topic
  autotuning which begs the question, why isn't the majority of
  software autotuned? The bulk of autotuning research projects falls
  prey of one of two shortcomings. Either they identify and develop a
  methodology for tuning a particular optimisation space but then fail
  to deliver on any usable product, or they deliver an autotuner which
  targets too specific of a niche to become mainstream. This projects
  attempts to address both of those shortcomings by expending great
  effort to deliver a working implementation which users can download
  and use without any setup costs, and by providing a modular and
  extensible framework which allows rapid targeting of new autotuning
  platforms, enabled by a shared autotuning logic and distributed
  training data.}


\section{Algorithmic Skeletons}

% Cole, M. I. (1989). Algorithmic Skeletons: Structured Management of
% Parallel Computation. Pitman London. Retrieved from
% http://homepages.inf.ed.ac.uk/mic/Pubs/skeletonbook.pdf
\TODO{Murray's thesis~\cite{Cole1989}.}

% Cole, M. I. (2004). Bringing skeletons out of the closet: a
% pragmatic manifesto for skeletal parallel programming. Parallel
% Computing, 30(3), 389–406. doi:10.1016/j.parco.2003.12.002
\TODO{Algorithmic Skeletons in academia~\cite{Cole2004}.}

% Striegnitz, J. (2000). Making C ++ Ready for Algorithmic Skeletons
% (Vol. 2000). Retrieved from http://www.fz-juelich.de/zam/FACT
\TODO{Early work towards C++ Alg. Skeletons\cite{Striegnitz2000}}


\section{The Problem}

\TODO{Why do we need autotuning? Describe necessary abstraction of low
  level tuning parameters, and demonstrate their effect on application
  performance.}


\section{Contributions}

\TODO{Itemised list of key technical and research contributions. Go
  all-out on the ``big sell''!}

\section{Structure}

The remainder of the document is structured as follows:
\fixme{\ldots}

\subsubsection{Notation and Terminology}

\TODO{Define mathematical notation used, and uncommon terms such as
  ``oracle''.}
