% INTRODUCTION
% ============
%
% An introduction to the document, clearing stating the hypothesis or
% objective of the project, motivation for the work and the results
% achieved. The structure of the remainder of the document should also
% be outlined.
GPUs enable massive performance through heterogeneous
parallelism. However, developing software for these devices is
challenging, as the programming models provided by OpenCL and CUDA
require a low level knowledge of the underlying architecture to
properly exploit the potential performance. SkelCL addresses this
programmability challenge by providing high level skeleton patterns
for common data parallel operations. This project demonstrates that
the parameters which are necessarily abstracted by such skeletons can
have a huge impact on performance. To demonstrate this, I present an
autotuner for selecting the \emph{workgroup size} of Stencil pattern
kernels.

\note{IMPORTANCE OF PARALLELISM}

% B. Catanzaro and K. Keutzer, “Parallel computing with patterns and
% frameworks,” XRDS Crossroads, ACM Mag. Students, vol. 17, no. 5,
% p. 22, 2010.
\todo{\cite{Catanzaro2010}}

\TODO{The rationale for autotuning long running iterative skeleton
  applications is that the longer the program runs, the smaller the
  training data we can reasonably expect the user to gather. A typical
  long running scientific program workload will only be run once, as
  there is no need to repeat a computation for which you already have
  the answer.}

\TODO{There is already a wealth of research literature on the topic
  autotuning which begs the question, why isn't the majority of
  software autotuned? The bulk of autotuning research projects falls
  prey of one of two shortcomings. Either they identify and develop a
  methodology for tuning a particular optimisation space but then fail
  to deliver on any usable product, or they deliver an autotuner which
  targets too specific of a niche to become mainstream. This projects
  attempts to address both of those shortcomings by expending great
  effort to deliver a working implementation which users can download
  and use without any setup costs, and by providing a modular and
  extensible framework which allows rapid targeting of new autotuning
  platforms, enabled by a shared autotuning logic and distributed
  training data.}

\section{SkelCL}

SkelCL\footnote{\url{http://skelcl.uni-muenster.de}} is an object
oriented C++ library that provides OpenCL implementations of data
parallel algorithmic skeletons for heterogeneous parallelism: Map,
Reduce, Scan, Zip, Stencil, and AllPairs. Skeletons are parameterised
with muscle functions by the user, which are compiled into OpenCL
kernels for execution on device hardware. The Vector and Matrix
container types transparently handle communication between the host
and device memory, and support partitioning for multi-GPU execution.

Each skeleton is represented by a template class, declared in a header
file detailing the public API. A private header file contains the
template definition. E.g. \texttt{SkelCL/Map.h} contains the Map
class, and \texttt{SkelCL/detail/MapDef.h} contains the
implementation. Non-trivial kernels are stored in separate source
files, e.g. \texttt{SkelCL/detail/MapKernel.cl}.

\lstset{language=C++}
\begin{lstlisting}[
  basicstyle=\scriptsize,
  caption={Example program to calculate dot product using SkelCL.}
]
#include <SkelCL/SkelCL.h>
#include <SkelCL/Vector.h>
#include <SkelCL/Zip.h>
#include <SkelCL/Reduce.h>

int main(int argc, char* argv[]) {
  // Initialise SkelCL to use any device.
  skelcl::init(skelcl::nDevices(1).deviceType(skelcl::device_type::ANY));

  // Define the skeleton objects.
  skelcl::Zip<int(int, int)> mult("int func(int x, int y) { return x * y; }");
  skelcl::Reduce<int(int)> sum("int func(int x, int y) { return x + y; }", "0");

  // Create two vectors A and B of length "n".
  const int n = 1024; skelcl::Vector<int> A(n), B(n);
  skelcl::Vector<int>::iterator a = A.begin(), b = B.begin();
  while (a != A.end()) { *a = rand() % n; ++a; *b = rand() % n; ++b; }

  // Invoke skeleton: x = A . B
  int x = sum(mult(A, B)).first();

  return 0;
}
\end{lstlisting}

\section{Structure}

The remainder of the document is structured as follows:
\TODO{\ldots}
