#!/usr/bin/env python2
#
# eval_e14 - Evaluate e14 data.
#
from __future__ import print_function

import csv
import itertools
import json
import math
import re

import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

# benchlib
import plot
import ml

import labm8 as lab
from labm8 import io
from labm8 import fs
from labm8 import math as labmath


WGSIZES= [
    [4, 8, 16, 24, 32, 48, 64],
    [4, 8, 16, 24, 32, 48, 64]
]

def get_data(path):
    with open(path) as file:
        return json.load(file)["data"]


def group_by_values(data, *keys):
    groups = {}

    for result in data:
        val = ", ".join([str(result[key]) for key in keys])

        if val in groups:
            groups[val].append(result)
        else:
            groups[val] = [result]

    return groups


def get_speedup(wg_str, result):
    key = "Speedup{0}".format(wg_str)
    return result[key]


def get_scenario_str(scenario):
    title = []
    benchmark = scenario["Benchmark"]
    devcount = scenario["DeviceCount"]
    devname = scenario["dev_name"]
    datasize = (scenario["DataHeight"], scenario["DataWidth"])

    title.append(benchmark)
    title.append("(" + "x".join([str(x) for x in datasize]) + "), ")

    if devcount > 1:
        title.append("%sx " % devcount)
    # Convert devname to human readable form.
    devname = " ".join(devname.split("_"))
    # Remove " cpu @ x.x GHZ" suffix:
    devname = re.sub(" cpu @.*$", "", devname)
    # Remove " r " and " tm " noisewords:
    devname = re.sub(" (r|tm) ", " ", devname)

    title.append(devname.title())

    return "".join([str(x) for x in title])


def process(scenarios, wgsizes, name):
    # Statistics collected across all scenarios.
    stats = {
        "num scenarios": [len(scenarios)],
        "num valid": [],
        "mean": [],
        "mean (valid)": [],
        "predicted": [],
        "diff (mean)": [],
        "diff (valid)": [],
        "diff (oracle)": [],
        "ratio (oracle)": []
    }

    # Add keys for each individual wg size.
    for wg in wgsizes:
        stats[wg[2]] = []

    for key in sorted(scenarios.keys()):
        if len(scenarios[key]) > 1:
            io.fatal("Scenarios should be unique!")

        scenario = scenarios[key][0]
        scenario_str = get_scenario_str(scenario)

        is_synthetic = scenario["Benchmark"][0] == "["

        results = [[x[1]] + scenario[x[2]] for x in wgsizes]
        valid_results = [x for x in results if x[1] != 0]

        mean = labmath.mean([x[1] for x in results])
        mean_valid = labmath.mean([x[1] for x in valid_results])

        e14_wg = scenario["PredictedLocalSize"]
        e14_key = "Speedup" + e14_wg
        e14_speedup = scenario[e14_key]

        oracle_wg = scenario["OracleLocalSize"]
        oracle_key = "Speedup" + oracle_wg
        oracle_speedup = scenario[oracle_key]

        stats["num valid"].append(len(valid_results))
        stats["mean"].append(mean)
        stats["mean (valid)"].append(mean_valid)
        stats["predicted"].append(e14_speedup[0])
        stats["diff (mean)"].append(e14_speedup[0] - mean)
        stats["diff (valid)"].append(e14_speedup[0] - mean_valid)
        stats["diff (oracle)"].append(e14_speedup[0] - oracle_speedup[0])
        try:
            stats["ratio (oracle)"].append(e14_speedup[0] / oracle_speedup[0])
        except ZeroDivisionError:
            stats["ratio (oracle)"].append(0)

        for wg in wgsizes:
            stats[wg[2]].append(scenario[wg[2]][0])

        # Plot results
        filename = re.sub("[, ]+", "_", scenario_str) + ".png"
        path = "./results/e14/speedups/" + filename
        if not is_synthetic and not fs.isfile(path):
            y = [x[1] for x in results]
            err = [x[2] for x in results]
            labels= [x[0] for x in results]

            plot.speedups(y, err=err, labels=labels, title=scenario_str,
                          usetex=False, path=path)

    for stat in sorted(stats):
        print(name, stat, "\t",
              min(stats[stat]), "\t",
              labmath.median(stats[stat]), "\t",
              labmath.mean(stats[stat]), "\t",
              max(stats[stat]))

def violinplot(data, wgsize_keys):
    """
    Create violin plot of all speedups.
    """
    benchmarks = group_by_values(data, "Benchmark")
    violindata = {}
    for benchmark in benchmarks:
        results = benchmarks[benchmark]
        speedups = []
        for result in results:
            speedups += [result[x][0] for x in wgsize_keys if result[x][0] > 0]
        if len(speedups):
            violindata[benchmark] = speedups

    labels = list(reversed(sorted(violindata)))
    y_vals = [violindata[x] for x in labels]

    # Set axis labels.
    syn, exp = 1, 1
    for i in range(len(labels)):
        if labels[i][0] == "[":
            labels[i] = "S" + str(syn)
            syn += 1
        else:
            labels[i] = "E" + str(exp)
            exp += 1

    fig, ax = plt.subplots()
    sns.violinplot(y_vals, names=labels, inner="points", ymin=0)
    plt.ylabel('Speedup')
    plt.xlabel('Programs')
    plt.title(("Distribution of speedups for {0} samples"
               .format(sum([len(x) for x in y_vals]))))
    ymin, ymax = 0, 10
    plt.ylim(ymin=ymin, ymax=ymax)
    ax.yaxis.set_ticks(np.arange(ymin, ymax + 1, 1.0))
    plt.savefig("./results/e14/violin-prog.png")
    plt.close()

    devices = group_by_values(data, "dev_name", "DeviceCount")
    violindata = {}
    for device in devices:
        results = devices[device]
        speedups = []
        for result in results:
            speedups += [result[x][0] for x in wgsize_keys if result[x][0] > 0]
        if len(speedups):
            violindata[device] = speedups

    labels = list(violindata)
    y_vals = [violindata[x] for x in labels]

    # Set axis labels.
    cpu, gpu = 1, 1
    for i in range(len(labels)):
        if labels[i][0] == "i":
            labels[i] = "CPU" + str(cpu)
            cpu += 1
        else:
            labels[i] = "GPU" + str(gpu)
            gpu += 1

    fig, ax = plt.subplots()
    sns.violinplot(y_vals, names=labels, inner="points", ymin=0)
    plt.ylabel('Speedup')
    plt.xlabel('Devices')
    plt.title(("Distribution of speedups for {0} samples"
               .format(sum([len(x) for x in y_vals]))))
    ymin, ymax = 0, 10
    plt.ylim(ymin=ymin, ymax=ymax)
    ax.yaxis.set_ticks(np.arange(ymin, ymax + 1, 1.0))
    plt.savefig("./results/e14/violin-dev.png")
    plt.close()


def hist_speedups(results):
    """
    Create histogram of oracle and omnitune speedups.
    """
    oracle_speedups, predicted_speedups = [], []
    for result in results:
        oracle_wgsize = result["OracleLocalSize"]
        oracle_speedup = result["Speedup" + oracle_wgsize][0]
        predicted_wgsize = result["PredictedLocalSize"]
        predicted_speedup = result["Speedup" + predicted_wgsize][0]

        if oracle_speedup > 0:
            oracle_speedups.append(oracle_speedup)
            predicted_speedups.append(predicted_speedup)

    fig, axes = plt.subplots(nrows=1, ncols=2)
    bins = np.logspace(0, 1, 20)
    axes[0].hist(oracle_speedups, bins)
    axes[0].set_xlabel("Oracle")
    axes[0].set_ylabel("Frequency")

    axes[1].hist(predicted_speedups, bins,
                 color=sns.desaturate("indianred", .75))
    axes[1].set_xlabel("OmniTune")

    ymin, ymax = 0, 35
    xticks = [1, 1.5, 2, 3, 4, 5, 6, 8, 10]

    for ax in axes:
        ax.set_xscale("log")
        ax.set_ylim([ymin, ymax])
        ax.set_xticks(xticks)
        ax.set_xticklabels(xticks)

    plt.figtext(.5, .935, "Distribution of speedups", ha='center')
    plt.savefig("./results/e14/hist.png")
    plt.close()


def plot_val_frequency(results, wgsizes):
    """
    Plot frequencies that parameter values are optimal or predicted by
    omnitune.
    """
    freqs = {}
    for wgsize in wgsizes:
        wgsize_str = wgsize[1]
        freqs[wgsize_str] = [0,0]

    # Create data.
    for result in results:
        oracle_wgsize = result["OracleLocalSize"]
        freqs[oracle_wgsize][0] += 1
        predicted_wgsize = result["PredictedLocalSize"]
        freqs[predicted_wgsize][1] += 1

    # Prune param values which are never picked.
    for wgsize in wgsizes:
        key = wgsize[1]
        if freqs[key][0] < 1 and freqs[key][1] < 1:
            del freqs[key]

    oracle_freqs = [x[0] for x in freqs.values()]
    predicted_freqs = [x[1] for x in freqs.values()]
    labels = freqs.keys()
    x_vals = np.arange(len(labels))

    # Sort by decreasing value.
    oracle_freqs, predicted_freqs = zip(*reversed(sorted(zip(oracle_freqs,
                                                             predicted_freqs),
                                                         key=lambda x: x[0])))
    width = 1.
    ax = plt.subplot(111)

    ax.bar(x_vals, oracle_freqs, width=width, label="Oracle")
    plt.xticks(x_vals + .5, labels, rotation=90)
    plt.ylabel('Frequency')
    plt.xlabel('Parameter values')
    # TODO: This is a shit plot title
    plt.title(("Optimal parameter values for {0} instances"
               .format(sum(oracle_freqs))))
    plt.savefig("./results/e14/freq.png")
    plt.close()


def clusters(results):
    oracle_x, oracle_y = [], []
    predicted_x, predicted_y = [], []
    for result in results:
        oracle_wgsize = [int(x) for x in result["OracleLocalSize"].split("x")]
        oracle_x.append(oracle_wgsize[0])
        oracle_y.append(oracle_wgsize[1])
        predicted_wgsize = [int(x) for x in result["PredictedLocalSize"].split("x")]
        predicted_x.append(predicted_wgsize[0])
        predicted_y.append(predicted_wgsize[1])

    fig, axes = plt.subplots(nrows=1, ncols=2)
    for ax in axes:
        ax.set_xlim([0, 80])
        ax.set_ylim([0, 70])

    axes[0].set_xlabel("Oracle")
    axes[1].set_xlabel("OmniTune")

    sns.kdeplot(np.array(oracle_x), np.array(oracle_y),
                gridsize=128, shade=True, ax=axes[0], cmap="Blues")
    sns.kdeplot(np.array(predicted_x), np.array(predicted_y),
                gridsize=128, shade=True, cmap="Reds")
    plt.figtext(.5, .935, "Clustering of parameter values", ha='center')
    plt.savefig("./results/e14/clusters.png")
    plt.close()


def cluster_invalid(results, wgsizes):
    x_val, y_val = [], []
    for result in results:
        for  wgsize in wgsizes:
            if result[wgsize[2]][0] == 0:
                x_val.append(wgsize[0][0])
                y_val.append(wgsize[0][1])

    sns.kdeplot(np.array(x_val), np.array(y_val), gridsize=64, shade=True)
    plt.figtext(.5, .935, "Invalid parameter values", ha='center')
    plt.savefig("./results/e14/invalid-clusters.png")
    plt.close()


def print_classifier_performance(results):
    oracle_speedups, predicted_speedups = [], []
    failed_count = 0

    for result in results:
        oracle_wgsize = result["OracleLocalSize"]
        oracle_speedup = result["Speedup" + oracle_wgsize][0]

        if oracle_speedup > 0:
            oracle_speedups.append(oracle_speedup)
            predicted_wgsize = result["PredictedLocalSize"]

            predicted_speedup = result["Speedup" + predicted_wgsize][0]
            if predicted_speedup == 0:
                failed_count += 1
                predicted_speedup = result["Speedup32x4"][0]

            predicted_speedups.append(predicted_speedup)

    oracle_mean = labmath.mean(oracle_speedups)
    predicted_mean = labmath.mean(predicted_speedups)
    mean_ratio = predicted_mean / oracle_mean

    oracle_median = labmath.median(oracle_speedups)
    predicted_median = labmath.median(predicted_speedups)
    median_ratio = predicted_median / oracle_median

    fail_rate = failed_count / float(len(oracle_speedups))

    print("    Num instances: ", len(oracle_speedups))
    print(("    Mean speedup:   {0:.2f} ({1:.2f}%) {2:.2f}"
           .format(predicted_mean, mean_ratio * 100, oracle_mean)))
    print(("    Median speedup: {0:.2f} ({1:.2f}%) {2:.2f}"
           .format(predicted_median, median_ratio * 100, oracle_median)))
    print("    Min speedup:    {0:.2f}".format(min(predicted_speedups)))
    print(("    Max speedup:    {0:.2f} ({1:.2f}%) {2:.2f}"
           .format(max(predicted_speedups),
                   (max(predicted_speedups) / max(oracle_speedups)) * 100,
                   max(oracle_speedups))))
    print("    Failure rate    {0:.2f}%".format(fail_rate * 100))


def get_oracle_speedups(results):
    oracle_speedups = []
    for result in results:
        oracle_wgsize = result["OracleLocalSize"]
        oracle_speedup = result["Speedup" + oracle_wgsize][0]
        if oracle_speedup > 1:
            oracle_speedups.append(oracle_speedup)
    return oracle_speedups


def print_speedups(speedups, oracle_speedups):
    mean = labmath.mean(speedups)
    oracle_mean = labmath.mean(oracle_speedups)
    mean_ratio = mean / oracle_mean

    median = labmath.median(speedups)
    oracle_median = labmath.median(oracle_speedups)
    median_ratio = median / oracle_median

    _min = min(speedups)
    oracle_min = min(oracle_speedups)
    min_ratio = _min / oracle_min

    _max = max(speedups)
    oracle_max = max(oracle_speedups)
    max_ratio = _max / oracle_max

    print("    Num instances: ", len(speedups))
    print(("    Mean speedup:   {0:.2f} ({1:.2f}%) {2:.2f}"
           .format(mean, mean_ratio * 100, oracle_mean)))
    print(("    Median speedup: {0:.2f} ({1:.2f}%) {2:.2f}"
           .format(median, median_ratio * 100, oracle_median)))
    print(("    Min speedup:    {0:.2f} ({1:.2f}) {2:.2f}"
           .format(_min, min_ratio * 100, oracle_min)))
    print(("    Max speedup:    {0:.2f} ({1:.2f}%) {2:.2f}"
           .format(_max, max_ratio * 100, oracle_max)))

def validate(training_data_json, test_data_json, k=10):
    training_paths, validation_paths = ml.split_arff("./results/e14/training.arff",
                                                     k=k)
    xspeedups, oracle_speedups = [], []
    for training,validation in zip(training_paths, validation_paths):
        training_data = ml.load_arff(training)
        test_data = ml.load_arff(validation)
        xspeedup, oracle_speedup = ml.evaluate_J48(training_data, test_data)
        xspeedups += xspeedup
        oracle_speedups += oracle_speedup

    print("\n{0}-Fold cross validation:".format(k))
    print_speedups(xspeedups, oracle_speedups)

    training_data = ml.load_arff("./results/e14/training.arff")
    test_data = ml.load_arff("./results/e14/test.arff")
    tspeedups, oracle_speedups = ml.evaluate_J48(training_data, test_data)

    print("\nTest programs:")
    print_speedups(tspeedups, oracle_speedups)

    # Plot classifier.
    # tree = ml.get_J48(training_data)
    # import weka.plot.graph as graph
    # graph.plot_dot_graph(tree.graph)


def plot_speedups(results, title=""):
    X = np.arange(len(results))

    plt.bar(X, results)
    plt.ylabel('Speedup')
    plt.xlabel('Programs')
    plt.title("Speedups of " + str(title))
    plt.axhline(y=1, color='k')

    plt.show()
    plt.savefig("results/e14/test_speedups.png")
    plt.close()


def zero_r(results, wgsizes):
    speedups = {}
    for wgsize in wgsizes:
        speedups[wgsize[2]] = []

    for result in results:
        for wgsize in wgsizes:
            speedup = result[wgsize[2]][0]
            if speedup > 0:
                speedups[wgsize[2]].append(speedup)

    data = []
    for wgsize in wgsizes:
        s = speedups[wgsize[2]]
        num_results = len(s)
        mean = labmath.mean(s)
        data.append((wgsize[1], num_results, mean, s))

    data = list(reversed(sorted(data, key=lambda x: x[1])))

    universal = data
    universal = list(reversed(sorted(universal, key=lambda x: x[2])))
    print([[x[0], x[1], x[2]] for x in universal])
    best = universal[0]
    zero_r = best[3]

    print("ZERO_R", best[0], "MIN", min(zero_r), "MAX", max(zero_r),
          "MEAN", labmath.mean(zero_r), "MEDIAN", labmath.median(zero_r))


def get_oracle_speedup(result):
    oracle_wg = result["OracleLocalSize"]
    oracle_key = "Speedup" + oracle_wg
    return result[oracle_key][0]

def foobar(results, path, wgs):
    outdata = []
    for result in results:
        d = {}
        out = []
        for wg in wgs:
            runtime_key = "Runtime" + wg
            out.append(result[runtime_key])

        oracle_key = "Runtime" + result["OracleLocalSize"]
        predicted_key = "Runtime" + result["PredictedLocalSize"]
        d["runtimes"] = out
        d["oracle"] = result[oracle_key]
        d["predicted"] = result[predicted_key]

        outdata.append(d)
    json.dump(outdata, open(path, "wb"))

BAD = None

def set_bad(results):
    global BAD
    bad = [False] * len(results[0]["speedups"])
    for result in results:
        for i,speedup in enumerate(result["speedups"]):
            if speedup == 0:
                bad[i] = True
    BAD = bad

def summarise(tag, speedups):
    print(tag, " "
          "{0:.2f}".format(min(speedups)),
          #"{0:.2f}".format(labmath.median(speedups)),
          "{0:.2f}".format(labmath.mean(speedups)),
          "{0:.2f}".format(max(speedups)))

def print_summary(results):
    global BAD

    num_good = len([x for x in BAD if not x])
    all_speedups = []

    for i,result in enumerate(results):
        speedups = []
        for j,speedup in enumerate(result["speedups"]):
            if not BAD[j]:
                speedups.append(speedup)
        all_speedups.append(speedups)

    for i in range(num_good):
        summarise("WG", [x[i] for x in all_speedups])

    predicted = [result["predicted"] for result in results]
    summarise("PREDICTED", predicted)
    oracle = [result["oracle"] for result in results]
    summarise("ORACLE", oracle)

    with open("test_speedups.txt", "wb") as file:
        for speedup in sorted(predicted):
            file.write("{0}\n".format(speedup))

    X = np.arange(len(predicted))
    plt.bar(X, sorted(predicted))
    plt.axhline(y=1, color='k')
    plt.tick_params(
        axis='x',          # changes apply to the x-axis
        which='both',      # both major and minor ticks are affected
        bottom='off',      # ticks along the bottom edge are off
        top='off',         # ticks along the top edge are off
        labelbottom='off')
    plt.xlabel("Programs")
    plt.ylabel("Speedup")
    plt.yticks(range(int(math.ceil(max(predicted))) + 1))
    plt.title("Speedup of predictions over best static value")
    plt.savefig("./results/e14/test_speedups.png")
    plt.close()


def oracle_speedups(results, path, wgs):
    outdata = []

    INDEX_OF_DEFAULT = 28

    for result in results:
        d = {}
        out = []
        oracle = result["oracle"]
        for i,runtime in enumerate(result["runtimes"]):
            if runtime > 0:
                speedup = oracle / runtime
            else:
                speedup = 0
            out.append(speedup)

        # print(",".join(sorted(["{0:.2f}".format(x) for x in out if x > 0], reverse=True)))

        d["speedups"] = out
        if result["predicted"] > 0:
            d["predicted"] = oracle / result["predicted"]
        else:
            d["predicted"] = oracle / result["runtimes"][INDEX_OF_DEFAULT]
        outdata.append(d)

    json.dump(outdata, open(path, "wb"))

def index_speedups(results, path, wgs, index):
    outdata = []

    INDEX_OF_DEFAULT = 28

    for result in results:
        d = {}
        out = []
        baseline = result["runtimes"][index]
        for i,runtime in enumerate(result["runtimes"]):
            if runtime > 0:
                speedup = baseline / runtime
            else:
                speedup = 0
            out.append(speedup)

        # print(",".join(sorted(["{0:.2f}".format(x) for x in out if x > 0], reverse=True)))

        d["speedups"] = out
        if result["predicted"] > 0:
            d["predicted"] = baseline / result["predicted"]
        else:
            d["predicted"] = baseline / result["runtimes"][INDEX_OF_DEFAULT]

        d["oracle"] = d["predicted"] / (baseline / result["oracle"])
        outdata.append(d)

    json.dump(outdata, open(path, "wb"))


def gen_heatmap(results, wgs):

    #for result in results:
    #print(wgs)

    pass


def main():
    """
    Generate plots.
    """
    wgsize_vals = list(itertools.product(*WGSIZES))
    wgsize_strs = ["{0}x{1}".format(*x) for x in wgsize_vals]
    wgsize_keys = ["Speedup{0}".format(x) for x in wgsize_strs]
    wgsizes = zip(wgsize_vals, wgsize_strs, wgsize_keys)

    alldata = get_data("results/e14/data.arff.json")

    training_data = [x for x in alldata if x["Benchmark"][0] == "["]
    test_data = [x for x in alldata if x not in training_data]

    allj = json.load(open("all.json"))
    training = json.load(open("training.json"))
    test = json.load(open("test.json"))

    #oracle_speedups(allj, "o-all.json", wgsize_strs)
    #oracle_speedups(training, "o-training.json", wgsize_strs)
    #oracle_speedups(test, "o-test.json", wgsize_strs)

    oall = json.load(open("o-all.json"))
    otraining = json.load(open("o-training.json"))
    otest = json.load(open("o-test.json"))

    set_bad(oall)

    # ZERO_R is (32, 4). Performance of oracle:
    #
    #           min  mean max
    # training: 0.17 0.81 1.00
    # test:     0.60 0.87 1.00
    # total:    0.17 0.81 1.00
    print(wgsize_vals.index((4, 32)))
    print(wgsize_vals.index((32, 4)))

    for i,bad in enumerate(BAD):
        if not bad:
            print("GOOD", i)

    zero_r_index = wgsize_vals.index((4, 32))
    index_speedups(allj, "i-all.json", wgsize_strs, zero_r_index)
    index_speedups(training, "i-training.json", wgsize_strs, zero_r_index)
    index_speedups(test, "i-test.json", wgsize_strs, zero_r_index)

    iall = json.load(open("i-all.json"))
    itraining = json.load(open("i-training.json"))
    itest = json.load(open("i-test.json"))

    gen_heatmap(oall, wgsizes)

    # print_summary(iall)
    io.info("TRAINING")
    # print_summary(itraining)
    io.info("TEST")
    print_summary(itest)

    lab.exit(0)


if __name__ == "__main__":
    main()
