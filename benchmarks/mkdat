#!/usr/bin/env python

import warnings

from subprocess import check_output
from scipy import stats
from math import sqrt
from sys import stdout
from operator import itemgetter, attrgetter, methodcaller

benchmarks = [x.strip() for x in open("benchmarks.txt").readlines()]
flags = [x.strip() for x in open("flags.txt").readlines()]

num_results = 200
speedup_baseline = ""

# Lookup cache
_ccache = {}
def lookup(benchmark, flags):
    if benchmark in _ccache:
        if flags in _ccache[benchmark]:
            return _ccache[benchmark][flags]
    else:
        _ccache[benchmark] = {}

    checksum = check_output('echo -e "{0}" | sha256sum | cut -d\' \' -f1'
                            .format(flags),
                            shell=True).decode("utf-8").strip()
    _ccache[benchmark][flags] = checksum
    return checksum


_tcache = {}
def times(benchmark, checksum):
    if benchmark in _tcache:
        if checksum in _tcache[benchmark]:
            return _tcache[benchmark][checksum]
    else:
        _tcache[benchmark] = {}

    times = [int(x.split()[0]) for x in
             open("dat/{0}/{1}"
                  .format(benchmark, checksum)).readlines()]
    _tcache[benchmark][checksum] = times
    return times


# Return the mean value of a list
def mean(l):
    if len(l):
        return sum(l) / len(l)
    else:
        return 0


def speedup(benchmark, time):
    baseline = mean(times(benchmark, lookup(benchmark, speedup_baseline)))
    return baseline / time


# Return the variance of a list
def variance(l):
    if len(l) > 1:
        differences = []
        for n in l:
            differences.append((n - mean(l)) ** 2)
        return sum(differences) / (len(differences) - 1)
    else:
        return 0


def stdev(l):
    return sqrt(variance(l))


def confinterval(l, c=0.95):
    if len(l) > 1:
        scale = stdev(l) / sqrt(len(l))

        # For small values of n, use a t-distribution:
        with warnings.catch_warnings():
            warnings.filterwarnings('error')
            try:
                return stats.t.interval(c, len(l) - 1, loc=mean(l), scale=scale)
            except:
                return mean(l), mean(l)
    else:
        return 0, 0


def FlagspeedupsVsBenchmarks(BENCHMARKS, FLAGS, f=stdout):
    if f != stdout:
        print("Writing '{0}'...".format(f.name))

    print(', '.join(["n", "benchmark"] +
                    ['{0} c1, {0}, {0} c2'.format(x) for x in FLAGS]), file=f)

    i = 0
    for benchmark in BENCHMARKS:
        i += 1
        T = []
        for flags in FLAGS:
            checksum = lookup(benchmark, flags)
            print(benchmark, flags, checksum)
            t = times(benchmark, checksum)
            m = mean(t)
            c = confinterval(t)
            s = [(speedup(benchmark, x)) for x in [c[1], m, c[0]]]
            s[0] = s[1] - s[0]
            s[2] -= s[1]
            T += [str(x) for x in s]
        print(', '.join([str(i), benchmark] + T), file=f)

def BenchmarkSpeedupVsFlags(FLAGS, BENCHMARKS, f=stdout):
    if f != stdout:
        print("Writing '{0}'...".format(f.name))

    print(', '.join(["n", "flags", "c1", "mean", "c2"]), file=f)

    R = []
    for flags in FLAGS:
        T = []
        for benchmark in BENCHMARKS:
            checksum = lookup(benchmark, flags)
            speedups = [speedup(benchmark, x) for x in
                        times(benchmark, checksum)]
            T += [speedup(benchmark, x) for x in times(benchmark, checksum)]
        c = confinterval(T)
        m = mean(T)
        R.append([flags, m - c[0], m, c[1] - m])

    R = reversed(sorted(R, key=itemgetter(2)))
    i = 0
    for r in R:
        i += 1
        print(', '.join([str(x) for x in [i] + r]), file=f)

#FlagspeedupsVsBenchmarks(benchmarks, flags,
#                         open('csv/basic.csv', 'w'))

BenchmarkSpeedupVsFlags(flags, benchmarks,
                        open('csv/basic.csv', 'w'))
